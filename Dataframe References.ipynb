{"cells":[{"cell_type":"code","source":["l = [('Alice',1)]\ndf = spark.createDataFrame(l)\ndf.collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">3</span><span class=\"ansired\">]: </span>[Row(_1=&apos;Alice&apos;, _2=1)]\n</div>"]}}],"execution_count":1},{"cell_type":"code","source":["df1 = spark.createDataFrame(l,['name','age'])\ndf1.collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">5</span><span class=\"ansired\">]: </span>[Row(name=&apos;Alice&apos;, age=1)]\n</div>"]}}],"execution_count":2},{"cell_type":"code","source":["D = [{'name':'Karthikeyan','age':'37'}]\ndf2 = spark.createDataFrame(D)\ndf2.collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">9</span><span class=\"ansired\">]: </span>[Row(age=&apos;37&apos;, name=&apos;Karthikeyan&apos;)]\n</div>"]}}],"execution_count":3},{"cell_type":"code","source":["rdd = sc.parallelize(l)\ndf3 = spark.createDataFrame(rdd)\ndf3.collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">12</span><span class=\"ansired\">]: </span>[Row(_1=&apos;Alice&apos;, _2=1)]\n</div>"]}}],"execution_count":4},{"cell_type":"code","source":["rdd = sc.parallelize(l)\ndf4 = spark.createDataFrame(rdd,['name','age'])\ndf4.collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">15</span><span class=\"ansired\">]: </span>[Row(name=&apos;Alice&apos;, age=1)]\n</div>"]}}],"execution_count":5},{"cell_type":"code","source":[">>> from pyspark.sql import Row\n>>> Person = Row('name', 'age')\n>>> person = rdd.map(lambda r: Person(*r))\n>>> df2 = spark.createDataFrame(person)\n>>> df2.collect()\n[Row(name='Alice', age=1)]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">20</span><span class=\"ansired\">]: </span>[Row(age=1, name=&apos;Alice&apos;)]\n</div>"]}}],"execution_count":6},{"cell_type":"code","source":["spark.range(1,7,2).collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">21</span><span class=\"ansired\">]: </span>[Row(id=1), Row(id=3), Row(id=5)]\n</div>"]}}],"execution_count":7},{"cell_type":"code","source":["spark.range(3).collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">22</span><span class=\"ansired\">]: </span>[Row(id=0), Row(id=1), Row(id=2)]\n</div>"]}}],"execution_count":8},{"cell_type":"code","source":["df.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+---+\n   _1| _2|\n+-----+---+\nAlice|  1|\n+-----+---+\n\n</div>"]}}],"execution_count":9},{"cell_type":"code","source":["df.createOrReplaceTempView(\"table\")\ndf5 = spark.sql(\"select * from table\")\ndf5.collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">27</span><span class=\"ansired\">]: </span>[Row(_1=&apos;Alice&apos;, _2=1)]\n</div>"]}}],"execution_count":10},{"cell_type":"code","source":["df.createOrReplaceTempView(\"temp1\")\ndf6 = spark.table(\"temp1\")\ndf6.collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">30</span><span class=\"ansired\">]: </span>[Row(_1=&apos;Alice&apos;, _2=1)]\n</div>"]}}],"execution_count":11},{"cell_type":"code","source":["strlen = spark.udf.register(\"strl\",lambda x:len(x))\nspark.sql(\"select strl('test')\").collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">37</span><span class=\"ansired\">]: </span>[Row(strl(test)=&apos;4&apos;)]\n</div>"]}}],"execution_count":12},{"cell_type":"code","source":["strlen = spark.udf.register(\"strl\",lambda x:len(x))\nspark.sql(\"select strlen('test')\").collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">AnalysisException</span>                         Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-3268544906203440&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      1</span> strlen <span class=\"ansiyellow\">=</span> spark<span class=\"ansiyellow\">.</span>udf<span class=\"ansiyellow\">.</span>register<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;strl&quot;</span><span class=\"ansiyellow\">,</span><span class=\"ansigreen\">lambda</span> x<span class=\"ansiyellow\">:</span>len<span class=\"ansiyellow\">(</span>x<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">----&gt; 2</span><span class=\"ansiyellow\"> </span>spark<span class=\"ansiyellow\">.</span>sql<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;select strlen(&apos;test&apos;)&quot;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>collect<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansicyan\">sql</span><span class=\"ansiblue\">(self, sqlQuery)</span>\n<span class=\"ansigreen\">    827</span>         <span class=\"ansiyellow\">[</span>Row<span class=\"ansiyellow\">(</span>f1<span class=\"ansiyellow\">=</span><span class=\"ansicyan\">1</span><span class=\"ansiyellow\">,</span> f2<span class=\"ansiyellow\">=</span><span class=\"ansiblue\">u&apos;row1&apos;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">,</span> Row<span class=\"ansiyellow\">(</span>f1<span class=\"ansiyellow\">=</span><span class=\"ansicyan\">2</span><span class=\"ansiyellow\">,</span> f2<span class=\"ansiyellow\">=</span><span class=\"ansiblue\">u&apos;row2&apos;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">,</span> Row<span class=\"ansiyellow\">(</span>f1<span class=\"ansiyellow\">=</span><span class=\"ansicyan\">3</span><span class=\"ansiyellow\">,</span> f2<span class=\"ansiyellow\">=</span><span class=\"ansiblue\">u&apos;row3&apos;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    828</span>         &quot;&quot;&quot;\n<span class=\"ansigreen\">--&gt; 829</span><span class=\"ansiyellow\">         </span><span class=\"ansigreen\">return</span> DataFrame<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">.</span>_jsparkSession<span class=\"ansiyellow\">.</span>sql<span class=\"ansiyellow\">(</span>sqlQuery<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">,</span> self<span class=\"ansiyellow\">.</span>_wrapped<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    830</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    831</span>     <span class=\"ansiyellow\">@</span>since<span class=\"ansiyellow\">(</span><span class=\"ansicyan\">2.0</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py</span> in <span class=\"ansicyan\">__call__</span><span class=\"ansiblue\">(self, *args)</span>\n<span class=\"ansigreen\">   1255</span>         answer <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>gateway_client<span class=\"ansiyellow\">.</span>send_command<span class=\"ansiyellow\">(</span>command<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1256</span>         return_value = get_return_value(\n<span class=\"ansigreen\">-&gt; 1257</span><span class=\"ansiyellow\">             answer, self.gateway_client, self.target_id, self.name)\n</span><span class=\"ansigreen\">   1258</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1259</span>         <span class=\"ansigreen\">for</span> temp_arg <span class=\"ansigreen\">in</span> temp_args<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansicyan\">deco</span><span class=\"ansiblue\">(*a, **kw)</span>\n<span class=\"ansigreen\">     67</span>                                              e.java_exception.getStackTrace()))\n<span class=\"ansigreen\">     68</span>             <span class=\"ansigreen\">if</span> s<span class=\"ansiyellow\">.</span>startswith<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;org.apache.spark.sql.AnalysisException: &apos;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 69</span><span class=\"ansiyellow\">                 </span><span class=\"ansigreen\">raise</span> AnalysisException<span class=\"ansiyellow\">(</span>s<span class=\"ansiyellow\">.</span>split<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;: &apos;</span><span class=\"ansiyellow\">,</span> <span class=\"ansicyan\">1</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">[</span><span class=\"ansicyan\">1</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">,</span> stackTrace<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     70</span>             <span class=\"ansigreen\">if</span> s<span class=\"ansiyellow\">.</span>startswith<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;org.apache.spark.sql.catalyst.analysis&apos;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     71</span>                 <span class=\"ansigreen\">raise</span> AnalysisException<span class=\"ansiyellow\">(</span>s<span class=\"ansiyellow\">.</span>split<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;: &apos;</span><span class=\"ansiyellow\">,</span> <span class=\"ansicyan\">1</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">[</span><span class=\"ansicyan\">1</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">,</span> stackTrace<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">AnalysisException</span>: &quot;Undefined function: &apos;strlen&apos;. This function is neither a registered temporary function nor a permanent function registered in the database &apos;default&apos;.; line 1 pos 7&quot;</div>"]}}],"execution_count":13},{"cell_type":"code","source":["spark.sql(\"select 'karthikeyan' as text \").select(strlen('text')).collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">40</span><span class=\"ansired\">]: </span>[Row(strl(text)=&apos;11&apos;)]\n</div>"]}}],"execution_count":14},{"cell_type":"code","source":["spark.sql(\"select 'karthikeyan' as text \").select(strl('text')).collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-3268544906203442&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">----&gt; 1</span><span class=\"ansiyellow\"> </span>spark<span class=\"ansiyellow\">.</span>sql<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;select &apos;karthikeyan&apos; as text &quot;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>select<span class=\"ansiyellow\">(</span>strl<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;text&apos;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>collect<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">NameError</span>: name &apos;strl&apos; is not defined</div>"]}}],"execution_count":15},{"cell_type":"code","source":["strlen = spark.udf.register('strl',lambda x: len(x))\nspark.sql(\"select strl('karthikeyan')\").collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">43</span><span class=\"ansired\">]: </span>[Row(strl(karthikeyan)=&apos;11&apos;)]\n</div>"]}}],"execution_count":16},{"cell_type":"code","source":["spark.sql(\"select 'karthikeyan' AS text\").select(strlen('text')).collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">48</span><span class=\"ansired\">]: </span>[Row(strl(text)=&apos;11&apos;)]\n</div>"]}}],"execution_count":17},{"cell_type":"code","source":["from pyspark.sql.types import IntegerType\n_ = spark.udf.register(\"strlen\",lambda x : len(x),IntegerType())\nspark.sql(\"select strlen('karthikeyan')\").collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">51</span><span class=\"ansired\">]: </span>[Row(strlen(karthikeyan)=11)]\n</div>"]}}],"execution_count":18},{"cell_type":"code","source":["from pyspark.sql.types import IntegerType\nfrom pyspark.sql.functions import udf\nslen = udf(lambda s:len(s),IntegerType())\nsef= spark.udf.register('slen1',slen)\nspark.sql(\"select slen1('test')\").collect()\nspark.sql(\"select 'karthikeyan' as text\").select(sef('text')).collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">61</span><span class=\"ansired\">]: </span>[Row(&lt;lambda&gt;(text)=11)]\n</div>"]}}],"execution_count":19},{"cell_type":"code","source":[">>> import random\n>>> from pyspark.sql.functions import udf\n>>> from pyspark.sql.types import IntegerType\n>>> random_udf = udf(lambda: random.randint(0, 100), IntegerType()).asNondeterministic()\n>>> new_random_udf = spark.udf.register(\"random_udf\", random_udf)\n>>> spark.sql(\"SELECT random_udf()\").collect()  # doctest: +SKIP\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">63</span><span class=\"ansired\">]: </span>[Row(random_udf()=13)]\n</div>"]}}],"execution_count":20},{"cell_type":"code","source":["df.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+---+\n   _1| _2|\n+-----+---+\nAlice|  1|\n+-----+---+\n\n</div>"]}}],"execution_count":21},{"cell_type":"code","source":["df.agg({\"_1\":\"max\"}).collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">65</span><span class=\"ansired\">]: </span>[Row(max(_1)=&apos;Alice&apos;)]\n</div>"]}}],"execution_count":22},{"cell_type":"code","source":["df.agg({\"_1\":\"min\"}).collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">67</span><span class=\"ansired\">]: </span>[Row(min(_1)=&apos;Alice&apos;)]\n</div>"]}}],"execution_count":23},{"cell_type":"code","source":["from pyspark.sql import functions as F\ndf.agg(F.min(\"_1\")).collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">70</span><span class=\"ansired\">]: </span>[Row(min(_1)=&apos;Alice&apos;)]\n</div>"]}}],"execution_count":24},{"cell_type":"code","source":["df.agg(F.max(\"_2\")).collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">71</span><span class=\"ansired\">]: </span>[Row(max(_2)=1)]\n</div>"]}}],"execution_count":25},{"cell_type":"code","source":["df.rdd.getNumPartitions()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">75</span><span class=\"ansired\">]: </span>8\n</div>"]}}],"execution_count":26},{"cell_type":"code","source":["df.coalesce(4).rdd.getNumPartitions()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">77</span><span class=\"ansired\">]: </span>4\n</div>"]}}],"execution_count":27},{"cell_type":"code","source":["from pyspark import HiveContext\nfrom pyspark import SQLContext \ndf = spark.createDataFrame([('a','b','c',1),('a','b','c',1),('a','b','c',1)],[\"col1\",\"col2\",\"col3\",\"col4\"])\n\ndf.select(df.colRegex(\"(Col1)?\")).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">AnalysisException</span>                         Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-3268544906203455&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      3</span> df <span class=\"ansiyellow\">=</span> spark<span class=\"ansiyellow\">.</span>createDataFrame<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">[</span><span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;a&apos;</span><span class=\"ansiyellow\">,</span><span class=\"ansiblue\">&apos;b&apos;</span><span class=\"ansiyellow\">,</span><span class=\"ansiblue\">&apos;c&apos;</span><span class=\"ansiyellow\">,</span><span class=\"ansicyan\">1</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">,</span><span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;a&apos;</span><span class=\"ansiyellow\">,</span><span class=\"ansiblue\">&apos;b&apos;</span><span class=\"ansiyellow\">,</span><span class=\"ansiblue\">&apos;c&apos;</span><span class=\"ansiyellow\">,</span><span class=\"ansicyan\">1</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">,</span><span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;a&apos;</span><span class=\"ansiyellow\">,</span><span class=\"ansiblue\">&apos;b&apos;</span><span class=\"ansiyellow\">,</span><span class=\"ansiblue\">&apos;c&apos;</span><span class=\"ansiyellow\">,</span><span class=\"ansicyan\">1</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">,</span><span class=\"ansiyellow\">[</span><span class=\"ansiblue\">&quot;col1&quot;</span><span class=\"ansiyellow\">,</span><span class=\"ansiblue\">&quot;col2&quot;</span><span class=\"ansiyellow\">,</span><span class=\"ansiblue\">&quot;col3&quot;</span><span class=\"ansiyellow\">,</span><span class=\"ansiblue\">&quot;col4&quot;</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      4</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">----&gt; 5</span><span class=\"ansiyellow\"> </span>df<span class=\"ansiyellow\">.</span>select<span class=\"ansiyellow\">(</span>df<span class=\"ansiyellow\">.</span>colRegex<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;(Col1)?&quot;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>show<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/sql/dataframe.py</span> in <span class=\"ansicyan\">colRegex</span><span class=\"ansiblue\">(self, colName)</span>\n<span class=\"ansigreen\">    981</span>         <span class=\"ansigreen\">if</span> <span class=\"ansigreen\">not</span> isinstance<span class=\"ansiyellow\">(</span>colName<span class=\"ansiyellow\">,</span> basestring<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    982</span>             <span class=\"ansigreen\">raise</span> ValueError<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;colName should be provided as string&quot;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 983</span><span class=\"ansiyellow\">         </span>jc <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>_jdf<span class=\"ansiyellow\">.</span>colRegex<span class=\"ansiyellow\">(</span>colName<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    984</span>         <span class=\"ansigreen\">return</span> Column<span class=\"ansiyellow\">(</span>jc<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    985</span> <span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py</span> in <span class=\"ansicyan\">__call__</span><span class=\"ansiblue\">(self, *args)</span>\n<span class=\"ansigreen\">   1255</span>         answer <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>gateway_client<span class=\"ansiyellow\">.</span>send_command<span class=\"ansiyellow\">(</span>command<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1256</span>         return_value = get_return_value(\n<span class=\"ansigreen\">-&gt; 1257</span><span class=\"ansiyellow\">             answer, self.gateway_client, self.target_id, self.name)\n</span><span class=\"ansigreen\">   1258</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1259</span>         <span class=\"ansigreen\">for</span> temp_arg <span class=\"ansigreen\">in</span> temp_args<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansicyan\">deco</span><span class=\"ansiblue\">(*a, **kw)</span>\n<span class=\"ansigreen\">     67</span>                                              e.java_exception.getStackTrace()))\n<span class=\"ansigreen\">     68</span>             <span class=\"ansigreen\">if</span> s<span class=\"ansiyellow\">.</span>startswith<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;org.apache.spark.sql.AnalysisException: &apos;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 69</span><span class=\"ansiyellow\">                 </span><span class=\"ansigreen\">raise</span> AnalysisException<span class=\"ansiyellow\">(</span>s<span class=\"ansiyellow\">.</span>split<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;: &apos;</span><span class=\"ansiyellow\">,</span> <span class=\"ansicyan\">1</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">[</span><span class=\"ansicyan\">1</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">,</span> stackTrace<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     70</span>             <span class=\"ansigreen\">if</span> s<span class=\"ansiyellow\">.</span>startswith<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;org.apache.spark.sql.catalyst.analysis&apos;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     71</span>                 <span class=\"ansigreen\">raise</span> AnalysisException<span class=\"ansiyellow\">(</span>s<span class=\"ansiyellow\">.</span>split<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;: &apos;</span><span class=\"ansiyellow\">,</span> <span class=\"ansicyan\">1</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">[</span><span class=\"ansicyan\">1</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">,</span> stackTrace<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">AnalysisException</span>: &apos;Cannot resolve column name &quot;(Col1)?&quot; among (col1, col2, col3, col4);&apos;</div>"]}}],"execution_count":28},{"cell_type":"code","source":["df.collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">89</span><span class=\"ansired\">]: </span>\n[Row(col1=&apos;a&apos;, col2=&apos;b&apos;, col3=&apos;c&apos;, col4=1),\n Row(col1=&apos;a&apos;, col2=&apos;b&apos;, col3=&apos;c&apos;, col4=1),\n Row(col1=&apos;a&apos;, col2=&apos;b&apos;, col3=&apos;c&apos;, col4=1)]\n</div>"]}}],"execution_count":29},{"cell_type":"code","source":["df.columns"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">90</span><span class=\"ansired\">]: </span>[&apos;col1&apos;, &apos;col2&apos;, &apos;col3&apos;, &apos;col4&apos;]\n</div>"]}}],"execution_count":30},{"cell_type":"code","source":["df.count()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">91</span><span class=\"ansired\">]: </span>3\n</div>"]}}],"execution_count":31},{"cell_type":"code","source":["df.createGlobalTempView(\"zzzz\")\ndf2 = spark.sql(\"select * from global_temp.zzzz\")\ndf2.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----+----+----+----+\ncol1|col2|col3|col4|\n+----+----+----+----+\n   a|   b|   c|   1|\n   a|   b|   c|   1|\n   a|   b|   c|   1|\n+----+----+----+----+\n\n</div>"]}}],"execution_count":32},{"cell_type":"code","source":["df.createGlobalTempView(\"zzzz\")\ndf2 = spark.sql(\"select * from global_temp.zzzz\")\ndf2.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">AnalysisException</span>                         Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-3268544906203460&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">----&gt; 1</span><span class=\"ansiyellow\"> </span>df<span class=\"ansiyellow\">.</span>createGlobalTempView<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;zzzz&quot;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      2</span> df2 <span class=\"ansiyellow\">=</span> spark<span class=\"ansiyellow\">.</span>sql<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;select * from global_temp.zzzz&quot;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      3</span> df2<span class=\"ansiyellow\">.</span>show<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/sql/dataframe.py</span> in <span class=\"ansicyan\">createGlobalTempView</span><span class=\"ansiblue\">(self, name)</span>\n<span class=\"ansigreen\">    199</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    200</span>         &quot;&quot;&quot;\n<span class=\"ansigreen\">--&gt; 201</span><span class=\"ansiyellow\">         </span>self<span class=\"ansiyellow\">.</span>_jdf<span class=\"ansiyellow\">.</span>createGlobalTempView<span class=\"ansiyellow\">(</span>name<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    202</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    203</span>     <span class=\"ansiyellow\">@</span>since<span class=\"ansiyellow\">(</span><span class=\"ansicyan\">2.2</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py</span> in <span class=\"ansicyan\">__call__</span><span class=\"ansiblue\">(self, *args)</span>\n<span class=\"ansigreen\">   1255</span>         answer <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>gateway_client<span class=\"ansiyellow\">.</span>send_command<span class=\"ansiyellow\">(</span>command<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1256</span>         return_value = get_return_value(\n<span class=\"ansigreen\">-&gt; 1257</span><span class=\"ansiyellow\">             answer, self.gateway_client, self.target_id, self.name)\n</span><span class=\"ansigreen\">   1258</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1259</span>         <span class=\"ansigreen\">for</span> temp_arg <span class=\"ansigreen\">in</span> temp_args<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansicyan\">deco</span><span class=\"ansiblue\">(*a, **kw)</span>\n<span class=\"ansigreen\">     69</span>                 <span class=\"ansigreen\">raise</span> AnalysisException<span class=\"ansiyellow\">(</span>s<span class=\"ansiyellow\">.</span>split<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;: &apos;</span><span class=\"ansiyellow\">,</span> <span class=\"ansicyan\">1</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">[</span><span class=\"ansicyan\">1</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">,</span> stackTrace<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     70</span>             <span class=\"ansigreen\">if</span> s<span class=\"ansiyellow\">.</span>startswith<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;org.apache.spark.sql.catalyst.analysis&apos;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 71</span><span class=\"ansiyellow\">                 </span><span class=\"ansigreen\">raise</span> AnalysisException<span class=\"ansiyellow\">(</span>s<span class=\"ansiyellow\">.</span>split<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;: &apos;</span><span class=\"ansiyellow\">,</span> <span class=\"ansicyan\">1</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">[</span><span class=\"ansicyan\">1</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">,</span> stackTrace<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     72</span>             <span class=\"ansigreen\">if</span> s<span class=\"ansiyellow\">.</span>startswith<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;org.apache.spark.sql.catalyst.parser.ParseException: &apos;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     73</span>                 <span class=\"ansigreen\">raise</span> ParseException<span class=\"ansiyellow\">(</span>s<span class=\"ansiyellow\">.</span>split<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;: &apos;</span><span class=\"ansiyellow\">,</span> <span class=\"ansicyan\">1</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">[</span><span class=\"ansicyan\">1</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">,</span> stackTrace<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">AnalysisException</span>: &quot;Temporary view &apos;zzzz&apos; already exists;&quot;</div>"]}}],"execution_count":33},{"cell_type":"code","source":["df.createOrReplaceGlobalTempView(\"zzzz\")\ndf2 = spark.sql(\"select * from global_temp.zzzz\")\ndf2.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----+----+----+----+\ncol1|col2|col3|col4|\n+----+----+----+----+\n   a|   b|   c|   1|\n   a|   b|   c|   1|\n   a|   b|   c|   1|\n+----+----+----+----+\n\n</div>"]}}],"execution_count":34},{"cell_type":"code","source":["df.select(\"age\", \"name\").collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">AnalysisException</span>                         Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-3268544906203462&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">----&gt; 1</span><span class=\"ansiyellow\"> </span>df<span class=\"ansiyellow\">.</span>select<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;age&quot;</span><span class=\"ansiyellow\">,</span> <span class=\"ansiblue\">&quot;name&quot;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>collect<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/sql/dataframe.py</span> in <span class=\"ansicyan\">select</span><span class=\"ansiblue\">(self, *cols)</span>\n<span class=\"ansigreen\">   1343</span>         <span class=\"ansiyellow\">[</span>Row<span class=\"ansiyellow\">(</span>name<span class=\"ansiyellow\">=</span><span class=\"ansiblue\">u&apos;Alice&apos;</span><span class=\"ansiyellow\">,</span> age<span class=\"ansiyellow\">=</span><span class=\"ansicyan\">12</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">,</span> Row<span class=\"ansiyellow\">(</span>name<span class=\"ansiyellow\">=</span><span class=\"ansiblue\">u&apos;Bob&apos;</span><span class=\"ansiyellow\">,</span> age<span class=\"ansiyellow\">=</span><span class=\"ansicyan\">15</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1344</span>         &quot;&quot;&quot;\n<span class=\"ansigreen\">-&gt; 1345</span><span class=\"ansiyellow\">         </span>jdf <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>_jdf<span class=\"ansiyellow\">.</span>select<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">.</span>_jcols<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">*</span>cols<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1346</span>         <span class=\"ansigreen\">return</span> DataFrame<span class=\"ansiyellow\">(</span>jdf<span class=\"ansiyellow\">,</span> self<span class=\"ansiyellow\">.</span>sql_ctx<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1347</span> <span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py</span> in <span class=\"ansicyan\">__call__</span><span class=\"ansiblue\">(self, *args)</span>\n<span class=\"ansigreen\">   1255</span>         answer <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>gateway_client<span class=\"ansiyellow\">.</span>send_command<span class=\"ansiyellow\">(</span>command<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1256</span>         return_value = get_return_value(\n<span class=\"ansigreen\">-&gt; 1257</span><span class=\"ansiyellow\">             answer, self.gateway_client, self.target_id, self.name)\n</span><span class=\"ansigreen\">   1258</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1259</span>         <span class=\"ansigreen\">for</span> temp_arg <span class=\"ansigreen\">in</span> temp_args<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansicyan\">deco</span><span class=\"ansiblue\">(*a, **kw)</span>\n<span class=\"ansigreen\">     67</span>                                              e.java_exception.getStackTrace()))\n<span class=\"ansigreen\">     68</span>             <span class=\"ansigreen\">if</span> s<span class=\"ansiyellow\">.</span>startswith<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;org.apache.spark.sql.AnalysisException: &apos;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 69</span><span class=\"ansiyellow\">                 </span><span class=\"ansigreen\">raise</span> AnalysisException<span class=\"ansiyellow\">(</span>s<span class=\"ansiyellow\">.</span>split<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;: &apos;</span><span class=\"ansiyellow\">,</span> <span class=\"ansicyan\">1</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">[</span><span class=\"ansicyan\">1</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">,</span> stackTrace<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     70</span>             <span class=\"ansigreen\">if</span> s<span class=\"ansiyellow\">.</span>startswith<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;org.apache.spark.sql.catalyst.analysis&apos;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     71</span>                 <span class=\"ansigreen\">raise</span> AnalysisException<span class=\"ansiyellow\">(</span>s<span class=\"ansiyellow\">.</span>split<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;: &apos;</span><span class=\"ansiyellow\">,</span> <span class=\"ansicyan\">1</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">[</span><span class=\"ansicyan\">1</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">,</span> stackTrace<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">AnalysisException</span>: &quot;cannot resolve &apos;&#96;age&#96;&apos; given input columns: [col1, col2, col3, col4];;\\n&apos;Project [&apos;age, &apos;name]\\n+- LogicalRDD [col1#338, col2#339, col3#340, col4#341L], false\\n&quot;</div>"]}}],"execution_count":35},{"cell_type":"code","source":[">>> l = [('Alice', 1)]\n>>> spark.createDataFrame(l).collect()\n[Row(_1='Alice', _2=1)]\n>>> df = spark.createDataFrame(l, ['name', 'age']).collect()\n[Row(name='Alice', age=1)]"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">104</span><span class=\"ansired\">]: </span>[Row(age=1, name=&apos;Alice&apos;)]\n</div>"]}}],"execution_count":36},{"cell_type":"code","source":["df = spark.createDataFrame(l)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":37},{"cell_type":"code","source":["l = [(10,'karthikeyan'),(20,'navaneethan')]\nm = [('karthikeyan',45),('nalini',89)]\ndf1 = spark.createDataFrame(l,['age','name'])\ndf2 = spark.createDataFrame(m,['name','height'])\ndf1.crossJoin(df2).collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">112</span><span class=\"ansired\">]: </span>\n[Row(age=10, name=&apos;karthikeyan&apos;, name=&apos;karthikeyan&apos;, height=45),\n Row(age=10, name=&apos;karthikeyan&apos;, name=&apos;nalini&apos;, height=89),\n Row(age=20, name=&apos;navaneethan&apos;, name=&apos;karthikeyan&apos;, height=45),\n Row(age=20, name=&apos;navaneethan&apos;, name=&apos;nalini&apos;, height=89)]\n</div>"]}}],"execution_count":38},{"cell_type":"code","source":["df1.crossJoin(df2.select('height')).select('age','name').collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">114</span><span class=\"ansired\">]: </span>\n[Row(age=10, name=&apos;karthikeyan&apos;),\n Row(age=10, name=&apos;karthikeyan&apos;),\n Row(age=20, name=&apos;navaneethan&apos;),\n Row(age=20, name=&apos;navaneethan&apos;)]\n</div>"]}}],"execution_count":39},{"cell_type":"code","source":["df1.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+-----------+\nage|       name|\n+---+-----------+\n 10|karthikeyan|\n 20|navaneethan|\n+---+-----------+\n\n</div>"]}}],"execution_count":40},{"cell_type":"code","source":["df1.crosstab('age','name').show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------+-----------+-----------+\nage_name|karthikeyan|navaneethan|\n+--------+-----------+-----------+\n      20|          0|          1|\n      10|          1|          0|\n+--------+-----------+-----------+\n\n</div>"]}}],"execution_count":41},{"cell_type":"code","source":["df1.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+-----------+\nage|       name|\n+---+-----------+\n 10|karthikeyan|\n 20|navaneethan|\n+---+-----------+\n\n</div>"]}}],"execution_count":42},{"cell_type":"code","source":["from pyspark import HiveContext\nfrom pyspark import SQLContext \ndf = spark.createDataFrame([('a','b','c',1),('a','b','c',1),('a','b','c',1)],[\"col1\",\"col2\",\"col3\",\"col4\"])\ndf.show()\ndf.crosstab(\"col1\",\"col2\").show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----+----+----+----+\ncol1|col2|col3|col4|\n+----+----+----+----+\n   a|   b|   c|   1|\n   a|   b|   c|   1|\n   a|   b|   c|   1|\n+----+----+----+----+\n\n+---------+---+\ncol1_col2|  b|\n+---------+---+\n        a|  3|\n+---------+---+\n\n</div>"]}}],"execution_count":43},{"cell_type":"code","source":["df.cube(\"col1\",\"col2\").count().orderBy(\"col1\", \"col2\").show()\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----+----+-----+\ncol1|col2|count|\n+----+----+-----+\nnull|null|    3|\nnull|   b|    3|\n   a|null|    3|\n   a|   b|    3|\n+----+----+-----+\n\n</div>"]}}],"execution_count":44},{"cell_type":"code","source":["df.describe('col1').show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------+----+\nsummary|col1|\n+-------+----+\n  count|   3|\n   mean|null|\n stddev|null|\n    min|   a|\n    max|   a|\n+-------+----+\n\n</div>"]}}],"execution_count":45},{"cell_type":"code","source":["from pyspark.sql import Row\ndf = sc.parallelize([ \\\nRow(name='Alice', age=5, height=80), \\\nRow(name='Alice', age=5, height=80), \\\nRow(name='Alice', age=10, height=80)]).toDF()\ndf.dropDuplicates().show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+------+-----+\nage|height| name|\n+---+------+-----+\n  5|    80|Alice|\n 10|    80|Alice|\n+---+------+-----+\n\n</div>"]}}],"execution_count":46},{"cell_type":"code","source":["df = spark.createDataFrame([(1, 'Peter', 1.79, 28,'M', 'Tiler'),\n                            (2, 'Fritz', 1.78, 45,'M', None),\n                            (3, 'Florence', 1.75, None, None, None),\n                            (4, 'Nicola',1.6, 33,'F', 'Dancer'),\n                            (5, 'Gregory', 1.8, 54,'M', 'Teacher'),\n                            (6, 'Steven', 1.82, None, 'M', None),\n                            (7, 'Dagmar', 1.7, 42,'F', 'Nurse'),]\n                           , ['id', 'Name', 'Height', 'Age', 'Gender', 'Occupation'])\n\ndf.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+--------+------+----+------+----------+\n id|    Name|Height| Age|Gender|Occupation|\n+---+--------+------+----+------+----------+\n  1|   Peter|  1.79|  28|     M|     Tiler|\n  2|   Fritz|  1.78|  45|     M|      null|\n  3|Florence|  1.75|null|  null|      null|\n  4|  Nicola|   1.6|  33|     F|    Dancer|\n  5| Gregory|   1.8|  54|     M|   Teacher|\n  6|  Steven|  1.82|null|     M|      null|\n  7|  Dagmar|   1.7|  42|     F|     Nurse|\n+---+--------+------+----+------+----------+\n\n</div>"]}}],"execution_count":47},{"cell_type":"code","source":["df2 = df.dropna(thresh=3,subset=('Age','Gender','Occupation'))\n\ndf2.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+-------+------+---+------+----------+\n id|   Name|Height|Age|Gender|Occupation|\n+---+-------+------+---+------+----------+\n  1|  Peter|  1.79| 28|     M|     Tiler|\n  4| Nicola|   1.6| 33|     F|    Dancer|\n  5|Gregory|   1.8| 54|     M|   Teacher|\n  7| Dagmar|   1.7| 42|     F|     Nurse|\n+---+-------+------+---+------+----------+\n\n</div>"]}}],"execution_count":48},{"cell_type":"code","source":["df.dtypes"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">149</span><span class=\"ansired\">]: </span>\n[(&apos;id&apos;, &apos;bigint&apos;),\n (&apos;Name&apos;, &apos;string&apos;),\n (&apos;Height&apos;, &apos;double&apos;),\n (&apos;Age&apos;, &apos;bigint&apos;),\n (&apos;Gender&apos;, &apos;string&apos;),\n (&apos;Occupation&apos;, &apos;string&apos;)]\n</div>"]}}],"execution_count":49},{"cell_type":"code","source":["df1 = spark.createDataFrame(\n[(\"a\", 1), (\"a\", 1), (\"a\", 1), (\"a\", 2), (\"b\",  3), (\"c\", 4)], [\"C1\", \"C2\"])\ndf2 = spark.createDataFrame([(\"a\", 1), (\"b\", 3)], [\"C1\", \"C2\"])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":50},{"cell_type":"code","source":["df1.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+---+\n C1| C2|\n+---+---+\n  a|  1|\n  a|  1|\n  a|  1|\n  a|  2|\n  b|  3|\n  c|  4|\n+---+---+\n\n</div>"]}}],"execution_count":51},{"cell_type":"code","source":["df2.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+---+\n C1| C2|\n+---+---+\n  a|  1|\n  b|  3|\n+---+---+\n\n</div>"]}}],"execution_count":52},{"cell_type":"code","source":["df1.exceptAll(df2).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+---+\n C1| C2|\n+---+---+\n  a|  1|\n  a|  1|\n  a|  2|\n  c|  4|\n+---+---+\n\n</div>"]}}],"execution_count":53},{"cell_type":"code","source":["df1.explain()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">== Physical Plan ==\n*(1) Scan ExistingRDD[C1#1387,C2#1388L]\n</div>"]}}],"execution_count":54},{"cell_type":"code","source":["df = spark.createDataFrame([(1, 'Peter', 1.79, 28,'M', 'Tiler'),\n                            (2, 'Fritz', 1.78, 45,'M', None),\n                            (3, 'Florence', 1.75, None, None, None),\n                            (4, 'Nicola',1.6, 33,'F', 'Dancer'),\n                            (5, 'Gregory', 1.8, 54,'M', 'Teacher'),\n                            (6, 'Steven', 1.82, None, 'M', None),\n                            (7, 'Dagmar', 1.7, 42,'F', 'Nurse'),]\n                           , ['id', 'Name', 'Height', 'Age', 'Gender', 'Occupation'])\n\ndf.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+--------+------+----+------+----------+\n id|    Name|Height| Age|Gender|Occupation|\n+---+--------+------+----+------+----------+\n  1|   Peter|  1.79|  28|     M|     Tiler|\n  2|   Fritz|  1.78|  45|     M|      null|\n  3|Florence|  1.75|null|  null|      null|\n  4|  Nicola|   1.6|  33|     F|    Dancer|\n  5| Gregory|   1.8|  54|     M|   Teacher|\n  6|  Steven|  1.82|null|     M|      null|\n  7|  Dagmar|   1.7|  42|     F|     Nurse|\n+---+--------+------+----+------+----------+\n\n</div>"]}}],"execution_count":55},{"cell_type":"code","source":["df.na.fill('10').show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+--------+------+----+------+----------+\n id|    Name|Height| Age|Gender|Occupation|\n+---+--------+------+----+------+----------+\n  1|   Peter|  1.79|  28|     M|     Tiler|\n  2|   Fritz|  1.78|  45|     M|        10|\n  3|Florence|  1.75|null|    10|        10|\n  4|  Nicola|   1.6|  33|     F|    Dancer|\n  5| Gregory|   1.8|  54|     M|   Teacher|\n  6|  Steven|  1.82|null|     M|        10|\n  7|  Dagmar|   1.7|  42|     F|     Nurse|\n+---+--------+------+----+------+----------+\n\n</div>"]}}],"execution_count":56},{"cell_type":"code","source":["df.na.fill(False).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+--------+------+----+------+----------+\n id|    Name|Height| Age|Gender|Occupation|\n+---+--------+------+----+------+----------+\n  1|   Peter|  1.79|  28|     M|     Tiler|\n  2|   Fritz|  1.78|  45|     M|      null|\n  3|Florence|  1.75|null|  null|      null|\n  4|  Nicola|   1.6|  33|     F|    Dancer|\n  5| Gregory|   1.8|  54|     M|   Teacher|\n  6|  Steven|  1.82|null|     M|      null|\n  7|  Dagmar|   1.7|  42|     F|     Nurse|\n+---+--------+------+----+------+----------+\n\n</div>"]}}],"execution_count":57},{"cell_type":"code","source":["df.na.fill({'Age':45,'Occupation':'Manager'}).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+--------+------+---+------+----------+\n id|    Name|Height|Age|Gender|Occupation|\n+---+--------+------+---+------+----------+\n  1|   Peter|  1.79| 28|     M|     Tiler|\n  2|   Fritz|  1.78| 45|     M|   Manager|\n  3|Florence|  1.75| 45|  null|   Manager|\n  4|  Nicola|   1.6| 33|     F|    Dancer|\n  5| Gregory|   1.8| 54|     M|   Teacher|\n  6|  Steven|  1.82| 45|     M|   Manager|\n  7|  Dagmar|   1.7| 42|     F|     Nurse|\n+---+--------+------+---+------+----------+\n\n</div>"]}}],"execution_count":58},{"cell_type":"code","source":["from pyspark.sql import functions as F\ndf.filter(\"name == 'Peter'\").show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+-----+------+---+------+----------+\n id| Name|Height|Age|Gender|Occupation|\n+---+-----+------+---+------+----------+\n  1|Peter|  1.79| 28|     M|     Tiler|\n+---+-----+------+---+------+----------+\n\n</div>"]}}],"execution_count":59},{"cell_type":"code","source":["df.first()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">173</span><span class=\"ansired\">]: </span>Row(id=1, Name=&apos;Peter&apos;, Height=1.79, Age=28, Gender=&apos;M&apos;, Occupation=&apos;Tiler&apos;)\n</div>"]}}],"execution_count":60},{"cell_type":"code","source":["def f(x):\n    print(x.name)\ndf.foreach(f)\n    "],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">Py4JJavaError</span>                             Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-1389959144656499&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      1</span> <span class=\"ansigreen\">def</span> f<span class=\"ansiyellow\">(</span>x<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      2</span>     print<span class=\"ansiyellow\">(</span>x<span class=\"ansiyellow\">.</span>name<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">----&gt; 3</span><span class=\"ansiyellow\"> </span>df<span class=\"ansiyellow\">.</span>foreach<span class=\"ansiyellow\">(</span>f<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      4</span> <span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/sql/dataframe.py</span> in <span class=\"ansicyan\">foreach</span><span class=\"ansiblue\">(self, f)</span>\n<span class=\"ansigreen\">    599</span>         <span class=\"ansiyellow\">&gt;&gt;</span><span class=\"ansiyellow\">&gt;</span> df<span class=\"ansiyellow\">.</span>foreach<span class=\"ansiyellow\">(</span>f<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    600</span>         &quot;&quot;&quot;\n<span class=\"ansigreen\">--&gt; 601</span><span class=\"ansiyellow\">         </span>self<span class=\"ansiyellow\">.</span>rdd<span class=\"ansiyellow\">.</span>foreach<span class=\"ansiyellow\">(</span>f<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    602</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    603</span>     <span class=\"ansiyellow\">@</span>since<span class=\"ansiyellow\">(</span><span class=\"ansicyan\">1.3</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/rdd.py</span> in <span class=\"ansicyan\">foreach</span><span class=\"ansiblue\">(self, f)</span>\n<span class=\"ansigreen\">    787</span>                 f<span class=\"ansiyellow\">(</span>x<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    788</span>             <span class=\"ansigreen\">return</span> iter<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">[</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 789</span><span class=\"ansiyellow\">         </span>self<span class=\"ansiyellow\">.</span>mapPartitions<span class=\"ansiyellow\">(</span>processPartition<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>count<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span>  <span class=\"ansired\"># Force evaluation</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    790</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    791</span>     <span class=\"ansigreen\">def</span> foreachPartition<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">,</span> f<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/rdd.py</span> in <span class=\"ansicyan\">count</span><span class=\"ansiblue\">(self)</span>\n<span class=\"ansigreen\">   1067</span>         <span class=\"ansicyan\">3</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1068</span>         &quot;&quot;&quot;\n<span class=\"ansigreen\">-&gt; 1069</span><span class=\"ansiyellow\">         </span><span class=\"ansigreen\">return</span> self<span class=\"ansiyellow\">.</span>mapPartitions<span class=\"ansiyellow\">(</span><span class=\"ansigreen\">lambda</span> i<span class=\"ansiyellow\">:</span> <span class=\"ansiyellow\">[</span>sum<span class=\"ansiyellow\">(</span><span class=\"ansicyan\">1</span> <span class=\"ansigreen\">for</span> _ <span class=\"ansigreen\">in</span> i<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>sum<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1070</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1071</span>     <span class=\"ansigreen\">def</span> stats<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/rdd.py</span> in <span class=\"ansicyan\">sum</span><span class=\"ansiblue\">(self)</span>\n<span class=\"ansigreen\">   1058</span>         <span class=\"ansicyan\">6.0</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1059</span>         &quot;&quot;&quot;\n<span class=\"ansigreen\">-&gt; 1060</span><span class=\"ansiyellow\">         </span><span class=\"ansigreen\">return</span> self<span class=\"ansiyellow\">.</span>mapPartitions<span class=\"ansiyellow\">(</span><span class=\"ansigreen\">lambda</span> x<span class=\"ansiyellow\">:</span> <span class=\"ansiyellow\">[</span>sum<span class=\"ansiyellow\">(</span>x<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>fold<span class=\"ansiyellow\">(</span><span class=\"ansicyan\">0</span><span class=\"ansiyellow\">,</span> operator<span class=\"ansiyellow\">.</span>add<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1061</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1062</span>     <span class=\"ansigreen\">def</span> count<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/rdd.py</span> in <span class=\"ansicyan\">fold</span><span class=\"ansiblue\">(self, zeroValue, op)</span>\n<span class=\"ansigreen\">    929</span>         <span class=\"ansired\"># zeroValue provided to each partition is unique from the one provided</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    930</span>         <span class=\"ansired\"># to the final reduce call</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 931</span><span class=\"ansiyellow\">         </span>vals <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>mapPartitions<span class=\"ansiyellow\">(</span>func<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>collect<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    932</span>         <span class=\"ansigreen\">return</span> reduce<span class=\"ansiyellow\">(</span>op<span class=\"ansiyellow\">,</span> vals<span class=\"ansiyellow\">,</span> zeroValue<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    933</span> <span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/rdd.py</span> in <span class=\"ansicyan\">collect</span><span class=\"ansiblue\">(self)</span>\n<span class=\"ansigreen\">    828</span>         <span class=\"ansired\"># Default path used in OSS Spark / for non-credential passthrough clusters:</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    829</span>         <span class=\"ansigreen\">with</span> SCCallSiteSync<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">.</span>context<span class=\"ansiyellow\">)</span> <span class=\"ansigreen\">as</span> css<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 830</span><span class=\"ansiyellow\">             </span>sock_info <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>ctx<span class=\"ansiyellow\">.</span>_jvm<span class=\"ansiyellow\">.</span>PythonRDD<span class=\"ansiyellow\">.</span>collectAndServe<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">.</span>_jrdd<span class=\"ansiyellow\">.</span>rdd<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    831</span>         <span class=\"ansigreen\">return</span> list<span class=\"ansiyellow\">(</span>_load_from_socket<span class=\"ansiyellow\">(</span>sock_info<span class=\"ansiyellow\">,</span> self<span class=\"ansiyellow\">.</span>_jrdd_deserializer<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    832</span> <span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py</span> in <span class=\"ansicyan\">__call__</span><span class=\"ansiblue\">(self, *args)</span>\n<span class=\"ansigreen\">   1255</span>         answer <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>gateway_client<span class=\"ansiyellow\">.</span>send_command<span class=\"ansiyellow\">(</span>command<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1256</span>         return_value = get_return_value(\n<span class=\"ansigreen\">-&gt; 1257</span><span class=\"ansiyellow\">             answer, self.gateway_client, self.target_id, self.name)\n</span><span class=\"ansigreen\">   1258</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1259</span>         <span class=\"ansigreen\">for</span> temp_arg <span class=\"ansigreen\">in</span> temp_args<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansicyan\">deco</span><span class=\"ansiblue\">(*a, **kw)</span>\n<span class=\"ansigreen\">     61</span>     <span class=\"ansigreen\">def</span> deco<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">*</span>a<span class=\"ansiyellow\">,</span> <span class=\"ansiyellow\">**</span>kw<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     62</span>         <span class=\"ansigreen\">try</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 63</span><span class=\"ansiyellow\">             </span><span class=\"ansigreen\">return</span> f<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">*</span>a<span class=\"ansiyellow\">,</span> <span class=\"ansiyellow\">**</span>kw<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     64</span>         <span class=\"ansigreen\">except</span> py4j<span class=\"ansiyellow\">.</span>protocol<span class=\"ansiyellow\">.</span>Py4JJavaError <span class=\"ansigreen\">as</span> e<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     65</span>             s <span class=\"ansiyellow\">=</span> e<span class=\"ansiyellow\">.</span>java_exception<span class=\"ansiyellow\">.</span>toString<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py</span> in <span class=\"ansicyan\">get_return_value</span><span class=\"ansiblue\">(answer, gateway_client, target_id, name)</span>\n<span class=\"ansigreen\">    326</span>                 raise Py4JJavaError(\n<span class=\"ansigreen\">    327</span>                     <span class=\"ansiblue\">&quot;An error occurred while calling {0}{1}{2}.\\n&quot;</span><span class=\"ansiyellow\">.</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 328</span><span class=\"ansiyellow\">                     format(target_id, &quot;.&quot;, name), value)\n</span><span class=\"ansigreen\">    329</span>             <span class=\"ansigreen\">else</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    330</span>                 raise Py4JError(\n\n<span class=\"ansired\">Py4JJavaError</span>: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 7 in stage 276.0 failed 1 times, most recent failure: Lost task 7.0 in stage 276.0 (TID 2967, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File &quot;/databricks/spark/python/pyspark/sql/types.py&quot;, line 1527, in __getattr__\n    idx = self.__fields__.index(item)\nValueError: &apos;name&apos; is not in list\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File &quot;/databricks/spark/python/pyspark/worker.py&quot;, line 403, in main\n    process()\n  File &quot;/databricks/spark/python/pyspark/worker.py&quot;, line 398, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File &quot;/databricks/spark/python/pyspark/rdd.py&quot;, line 2516, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File &quot;/databricks/spark/python/pyspark/rdd.py&quot;, line 2516, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File &quot;/databricks/spark/python/pyspark/rdd.py&quot;, line 2516, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File &quot;/databricks/spark/python/pyspark/rdd.py&quot;, line 352, in func\n    return f(iterator)\n  File &quot;/databricks/spark/python/pyspark/rdd.py&quot;, line 787, in processPartition\n    f(x)\n  File &quot;/databricks/spark/python/pyspark/util.py&quot;, line 99, in wrapper\n    return f(*args, **kwargs)\n  File &quot;&lt;command-1389959144656499&gt;&quot;, line 2, in f\n  File &quot;/databricks/spark/python/pyspark/sql/types.py&quot;, line 1532, in __getattr__\n    raise AttributeError(item)\nAttributeError: name\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:490)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:626)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:609)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:444)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:891)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:961)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:961)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2281)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2281)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:139)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:112)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$13.apply(Executor.scala:497)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1481)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:503)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:2355)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2343)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2342)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2342)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:1096)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:1096)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1096)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2574)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2522)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2510)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:893)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2240)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2262)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2281)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2306)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:961)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:379)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:960)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:209)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File &quot;/databricks/spark/python/pyspark/sql/types.py&quot;, line 1527, in __getattr__\n    idx = self.__fields__.index(item)\nValueError: &apos;name&apos; is not in list\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File &quot;/databricks/spark/python/pyspark/worker.py&quot;, line 403, in main\n    process()\n  File &quot;/databricks/spark/python/pyspark/worker.py&quot;, line 398, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File &quot;/databricks/spark/python/pyspark/rdd.py&quot;, line 2516, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File &quot;/databricks/spark/python/pyspark/rdd.py&quot;, line 2516, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File &quot;/databricks/spark/python/pyspark/rdd.py&quot;, line 2516, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File &quot;/databricks/spark/python/pyspark/rdd.py&quot;, line 352, in func\n    return f(iterator)\n  File &quot;/databricks/spark/python/pyspark/rdd.py&quot;, line 787, in processPartition\n    f(x)\n  File &quot;/databricks/spark/python/pyspark/util.py&quot;, line 99, in wrapper\n    return f(*args, **kwargs)\n  File &quot;&lt;command-1389959144656499&gt;&quot;, line 2, in f\n  File &quot;/databricks/spark/python/pyspark/sql/types.py&quot;, line 1532, in __getattr__\n    raise AttributeError(item)\nAttributeError: name\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:490)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:626)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRunner.scala:609)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:444)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:891)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableOnce$class.to(TraversableOnce.scala:310)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:302)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:289)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:961)\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1$$anonfun$13.apply(RDD.scala:961)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2281)\n\tat org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2281)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:139)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:112)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$13.apply(Executor.scala:497)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1481)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:503)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n</div>"]}}],"execution_count":61},{"cell_type":"code","source":["df.groupBy().avg().collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">176</span><span class=\"ansired\">]: </span>[Row(avg(id)=4.0, avg(Height)=1.7485714285714287, avg(Age)=40.4)]\n</div>"]}}],"execution_count":62},{"cell_type":"code","source":["sorted(df.groupBy('name').agg({'age': 'mean'}).collect())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">177</span><span class=\"ansired\">]: </span>\n[Row(name=&apos;Dagmar&apos;, avg(age)=42.0),\n Row(name=&apos;Florence&apos;, avg(age)=None),\n Row(name=&apos;Fritz&apos;, avg(age)=45.0),\n Row(name=&apos;Gregory&apos;, avg(age)=54.0),\n Row(name=&apos;Nicola&apos;, avg(age)=33.0),\n Row(name=&apos;Peter&apos;, avg(age)=28.0),\n Row(name=&apos;Steven&apos;, avg(age)=None)]\n</div>"]}}],"execution_count":63},{"cell_type":"code","source":["df.head()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">178</span><span class=\"ansired\">]: </span>Row(id=1, Name=&apos;Peter&apos;, Height=1.79, Age=28, Gender=&apos;M&apos;, Occupation=&apos;Tiler&apos;)\n</div>"]}}],"execution_count":64},{"cell_type":"code","source":["df.head()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">179</span><span class=\"ansired\">]: </span>Row(id=1, Name=&apos;Peter&apos;, Height=1.79, Age=28, Gender=&apos;M&apos;, Occupation=&apos;Tiler&apos;)\n</div>"]}}],"execution_count":65},{"cell_type":"code","source":["df.sort(df.Height.desc()).collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">181</span><span class=\"ansired\">]: </span>\n[Row(id=6, Name=&apos;Steven&apos;, Height=1.82, Age=None, Gender=&apos;M&apos;, Occupation=None),\n Row(id=5, Name=&apos;Gregory&apos;, Height=1.8, Age=54, Gender=&apos;M&apos;, Occupation=&apos;Teacher&apos;),\n Row(id=1, Name=&apos;Peter&apos;, Height=1.79, Age=28, Gender=&apos;M&apos;, Occupation=&apos;Tiler&apos;),\n Row(id=2, Name=&apos;Fritz&apos;, Height=1.78, Age=45, Gender=&apos;M&apos;, Occupation=None),\n Row(id=3, Name=&apos;Florence&apos;, Height=1.75, Age=None, Gender=None, Occupation=None),\n Row(id=7, Name=&apos;Dagmar&apos;, Height=1.7, Age=42, Gender=&apos;F&apos;, Occupation=&apos;Nurse&apos;),\n Row(id=4, Name=&apos;Nicola&apos;, Height=1.6, Age=33, Gender=&apos;F&apos;, Occupation=&apos;Dancer&apos;)]\n</div>"]}}],"execution_count":66},{"cell_type":"code","source":["df.sort(\"age\", ascending=False).collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">184</span><span class=\"ansired\">]: </span>\n[Row(id=5, Name=&apos;Gregory&apos;, Height=1.8, Age=54, Gender=&apos;M&apos;, Occupation=&apos;Teacher&apos;),\n Row(id=2, Name=&apos;Fritz&apos;, Height=1.78, Age=45, Gender=&apos;M&apos;, Occupation=None),\n Row(id=7, Name=&apos;Dagmar&apos;, Height=1.7, Age=42, Gender=&apos;F&apos;, Occupation=&apos;Nurse&apos;),\n Row(id=4, Name=&apos;Nicola&apos;, Height=1.6, Age=33, Gender=&apos;F&apos;, Occupation=&apos;Dancer&apos;),\n Row(id=1, Name=&apos;Peter&apos;, Height=1.79, Age=28, Gender=&apos;M&apos;, Occupation=&apos;Tiler&apos;),\n Row(id=3, Name=&apos;Florence&apos;, Height=1.75, Age=None, Gender=None, Occupation=None),\n Row(id=6, Name=&apos;Steven&apos;, Height=1.82, Age=None, Gender=&apos;M&apos;, Occupation=None)]\n</div>"]}}],"execution_count":67},{"cell_type":"code","source":["df.repartitionByRange(2, \"age\").rdd.getNumPartitions()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">185</span><span class=\"ansired\">]: </span>2\n</div>"]}}],"execution_count":68},{"cell_type":"code","source":["df.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+--------+------+----+------+----------+\n id|    Name|Height| Age|Gender|Occupation|\n+---+--------+------+----+------+----------+\n  1|   Peter|  1.79|  28|     M|     Tiler|\n  2|   Fritz|  1.78|  45|     M|      null|\n  3|Florence|  1.75|null|  null|      null|\n  4|  Nicola|   1.6|  33|     F|    Dancer|\n  5| Gregory|   1.8|  54|     M|   Teacher|\n  6|  Steven|  1.82|null|     M|      null|\n  7|  Dagmar|   1.7|  42|     F|     Nurse|\n+---+--------+------+----+------+----------+\n\n</div>"]}}],"execution_count":69},{"cell_type":"code","source":["df.na.replace(45,99).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+--------+------+----+------+----------+\n id|    Name|Height| Age|Gender|Occupation|\n+---+--------+------+----+------+----------+\n  1|   Peter|  1.79|  28|     M|     Tiler|\n  2|   Fritz|  1.78|  99|     M|      null|\n  3|Florence|  1.75|null|  null|      null|\n  4|  Nicola|   1.6|  33|     F|    Dancer|\n  5| Gregory|   1.8|  54|     M|   Teacher|\n  6|  Steven|  1.82|null|     M|      null|\n  7|  Dagmar|   1.7|  42|     F|     Nurse|\n+---+--------+------+----+------+----------+\n\n</div>"]}}],"execution_count":70},{"cell_type":"code","source":["df.na.replace('Peter','Karthikeyan').show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+-----------+------+----+------+----------+\n id|       Name|Height| Age|Gender|Occupation|\n+---+-----------+------+----+------+----------+\n  1|Karthikeyan|  1.79|  28|     M|     Tiler|\n  2|      Fritz|  1.78|  45|     M|      null|\n  3|   Florence|  1.75|null|  null|      null|\n  4|     Nicola|   1.6|  33|     F|    Dancer|\n  5|    Gregory|   1.8|  54|     M|   Teacher|\n  6|     Steven|  1.82|null|     M|      null|\n  7|     Dagmar|   1.7|  42|     F|     Nurse|\n+---+-----------+------+----+------+----------+\n\n</div>"]}}],"execution_count":71},{"cell_type":"code","source":["df.rollup('Age').count().show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----+-----+\n Age|count|\n+----+-----+\n  45|    1|\nnull|    7|\n  42|    1|\n  33|    1|\n  28|    1|\n  54|    1|\nnull|    2|\n+----+-----+\n\n</div>"]}}],"execution_count":72},{"cell_type":"code","source":["df = spark.createDataFrame([(1, 'Peter', 1.79, 28,'M', 'Tiler'),\n                            (2, 'Fritz', 1.78, 45,'M', None),\n                            (3, 'Florence', 1.75, None, None, None),\n                            (4, 'Nicola',1.6, 33,'F', 'Dancer'),\n                            (5, 'Gregory', 1.8, 54,'M', 'Teacher'),\n                            (6, 'Steven', 1.82, None, 'M', None),\n                            (7, 'Dagmar', 1.7, 42,'F', 'Nurse'),]\n                           , ['id', 'Name', 'Height', 'Age', 'Gender', 'Occupation'])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":73},{"cell_type":"code","source":["df.printSchema()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- id: long (nullable = true)\n-- Name: string (nullable = true)\n-- Height: double (nullable = true)\n-- Age: long (nullable = true)\n-- Gender: string (nullable = true)\n-- Occupation: string (nullable = true)\n\n</div>"]}}],"execution_count":74},{"cell_type":"code","source":["df.registerTempTable(\"people\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":75},{"cell_type":"code","source":["df2=spark.sql(\"select * from people\")\ndf2.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+--------+------+----+------+----------+\n id|    Name|Height| Age|Gender|Occupation|\n+---+--------+------+----+------+----------+\n  1|   Peter|  1.79|  28|     M|     Tiler|\n  2|   Fritz|  1.78|  45|     M|      null|\n  3|Florence|  1.75|null|  null|      null|\n  4|  Nicola|   1.6|  33|     F|    Dancer|\n  5| Gregory|   1.8|  54|     M|   Teacher|\n  6|  Steven|  1.82|null|     M|      null|\n  7|  Dagmar|   1.7|  42|     F|     Nurse|\n+---+--------+------+----+------+----------+\n\n</div>"]}}],"execution_count":76},{"cell_type":"code","source":["spark.catalog.dropTempView(\"people\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":77},{"cell_type":"code","source":["spark.sql(\"select * from people\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">AnalysisException</span>                         Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-1386788786254032&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">----&gt; 1</span><span class=\"ansiyellow\"> </span>spark<span class=\"ansiyellow\">.</span>sql<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;select * from people&quot;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansicyan\">sql</span><span class=\"ansiblue\">(self, sqlQuery)</span>\n<span class=\"ansigreen\">    827</span>         <span class=\"ansiyellow\">[</span>Row<span class=\"ansiyellow\">(</span>f1<span class=\"ansiyellow\">=</span><span class=\"ansicyan\">1</span><span class=\"ansiyellow\">,</span> f2<span class=\"ansiyellow\">=</span><span class=\"ansiblue\">u&apos;row1&apos;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">,</span> Row<span class=\"ansiyellow\">(</span>f1<span class=\"ansiyellow\">=</span><span class=\"ansicyan\">2</span><span class=\"ansiyellow\">,</span> f2<span class=\"ansiyellow\">=</span><span class=\"ansiblue\">u&apos;row2&apos;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">,</span> Row<span class=\"ansiyellow\">(</span>f1<span class=\"ansiyellow\">=</span><span class=\"ansicyan\">3</span><span class=\"ansiyellow\">,</span> f2<span class=\"ansiyellow\">=</span><span class=\"ansiblue\">u&apos;row3&apos;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    828</span>         &quot;&quot;&quot;\n<span class=\"ansigreen\">--&gt; 829</span><span class=\"ansiyellow\">         </span><span class=\"ansigreen\">return</span> DataFrame<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">.</span>_jsparkSession<span class=\"ansiyellow\">.</span>sql<span class=\"ansiyellow\">(</span>sqlQuery<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">,</span> self<span class=\"ansiyellow\">.</span>_wrapped<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    830</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    831</span>     <span class=\"ansiyellow\">@</span>since<span class=\"ansiyellow\">(</span><span class=\"ansicyan\">2.0</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py</span> in <span class=\"ansicyan\">__call__</span><span class=\"ansiblue\">(self, *args)</span>\n<span class=\"ansigreen\">   1255</span>         answer <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>gateway_client<span class=\"ansiyellow\">.</span>send_command<span class=\"ansiyellow\">(</span>command<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1256</span>         return_value = get_return_value(\n<span class=\"ansigreen\">-&gt; 1257</span><span class=\"ansiyellow\">             answer, self.gateway_client, self.target_id, self.name)\n</span><span class=\"ansigreen\">   1258</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1259</span>         <span class=\"ansigreen\">for</span> temp_arg <span class=\"ansigreen\">in</span> temp_args<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansicyan\">deco</span><span class=\"ansiblue\">(*a, **kw)</span>\n<span class=\"ansigreen\">     67</span>                                              e.java_exception.getStackTrace()))\n<span class=\"ansigreen\">     68</span>             <span class=\"ansigreen\">if</span> s<span class=\"ansiyellow\">.</span>startswith<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;org.apache.spark.sql.AnalysisException: &apos;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 69</span><span class=\"ansiyellow\">                 </span><span class=\"ansigreen\">raise</span> AnalysisException<span class=\"ansiyellow\">(</span>s<span class=\"ansiyellow\">.</span>split<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;: &apos;</span><span class=\"ansiyellow\">,</span> <span class=\"ansicyan\">1</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">[</span><span class=\"ansicyan\">1</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">,</span> stackTrace<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     70</span>             <span class=\"ansigreen\">if</span> s<span class=\"ansiyellow\">.</span>startswith<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;org.apache.spark.sql.catalyst.analysis&apos;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     71</span>                 <span class=\"ansigreen\">raise</span> AnalysisException<span class=\"ansiyellow\">(</span>s<span class=\"ansiyellow\">.</span>split<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;: &apos;</span><span class=\"ansiyellow\">,</span> <span class=\"ansicyan\">1</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">[</span><span class=\"ansicyan\">1</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">,</span> stackTrace<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">AnalysisException</span>: &apos;Table or view not found: people; line 1 pos 14&apos;</div>"]}}],"execution_count":78},{"cell_type":"code","source":["df.repartition(10).rdd.getNumPartitions()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">9</span><span class=\"ansired\">]: </span>10\n</div>"]}}],"execution_count":79},{"cell_type":"code","source":["data = df.union(df)\ndata.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+--------+------+----+------+----------+\n id|    Name|Height| Age|Gender|Occupation|\n+---+--------+------+----+------+----------+\n  1|   Peter|  1.79|  28|     M|     Tiler|\n  2|   Fritz|  1.78|  45|     M|      null|\n  3|Florence|  1.75|null|  null|      null|\n  4|  Nicola|   1.6|  33|     F|    Dancer|\n  5| Gregory|   1.8|  54|     M|   Teacher|\n  6|  Steven|  1.82|null|     M|      null|\n  7|  Dagmar|   1.7|  42|     F|     Nurse|\n  1|   Peter|  1.79|  28|     M|     Tiler|\n  2|   Fritz|  1.78|  45|     M|      null|\n  3|Florence|  1.75|null|  null|      null|\n  4|  Nicola|   1.6|  33|     F|    Dancer|\n  5| Gregory|   1.8|  54|     M|   Teacher|\n  6|  Steven|  1.82|null|     M|      null|\n  7|  Dagmar|   1.7|  42|     F|     Nurse|\n+---+--------+------+----+------+----------+\n\n</div>"]}}],"execution_count":80},{"cell_type":"code","source":["data = data.repartition(7,'Age')\ndata.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+--------+------+----+------+----------+\n id|    Name|Height| Age|Gender|Occupation|\n+---+--------+------+----+------+----------+\n  2|   Fritz|  1.78|  45|     M|      null|\n  3|Florence|  1.75|null|  null|      null|\n  6|  Steven|  1.82|null|     M|      null|\n  2|   Fritz|  1.78|  45|     M|      null|\n  3|Florence|  1.75|null|  null|      null|\n  6|  Steven|  1.82|null|     M|      null|\n  5| Gregory|   1.8|  54|     M|   Teacher|\n  5| Gregory|   1.8|  54|     M|   Teacher|\n  1|   Peter|  1.79|  28|     M|     Tiler|\n  1|   Peter|  1.79|  28|     M|     Tiler|\n  4|  Nicola|   1.6|  33|     F|    Dancer|\n  7|  Dagmar|   1.7|  42|     F|     Nurse|\n  4|  Nicola|   1.6|  33|     F|    Dancer|\n  7|  Dagmar|   1.7|  42|     F|     Nurse|\n+---+--------+------+----+------+----------+\n\n</div>"]}}],"execution_count":81},{"cell_type":"code","source":["df.na.replace('Fritz','Karthikeyan').show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+-----------+------+----+------+----------+\n id|       Name|Height| Age|Gender|Occupation|\n+---+-----------+------+----+------+----------+\n  1|      Peter|  1.79|  28|     M|     Tiler|\n  2|Karthikeyan|  1.78|  45|     M|      null|\n  3|   Florence|  1.75|null|  null|      null|\n  4|     Nicola|   1.6|  33|     F|    Dancer|\n  5|    Gregory|   1.8|  54|     M|   Teacher|\n  6|     Steven|  1.82|null|     M|      null|\n  7|     Dagmar|   1.7|  42|     F|     Nurse|\n+---+-----------+------+----+------+----------+\n\n</div>"]}}],"execution_count":82},{"cell_type":"code","source":["df.rollup('Gender').count().show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------+-----+\nGender|count|\n+------+-----+\n  null|    7|\n     F|    2|\n     M|    4|\n  null|    1|\n+------+-----+\n\n</div>"]}}],"execution_count":83},{"cell_type":"code","source":["df.shema()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">AttributeError</span>                            Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-1386788786254038&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">----&gt; 1</span><span class=\"ansiyellow\"> </span>df<span class=\"ansiyellow\">.</span>shema<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/sql/dataframe.py</span> in <span class=\"ansicyan\">__getattr__</span><span class=\"ansiblue\">(self, name)</span>\n<span class=\"ansigreen\">   1323</span>         <span class=\"ansigreen\">if</span> name <span class=\"ansigreen\">not</span> <span class=\"ansigreen\">in</span> self<span class=\"ansiyellow\">.</span>columns<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1324</span>             raise AttributeError(\n<span class=\"ansigreen\">-&gt; 1325</span><span class=\"ansiyellow\">                 &quot;&apos;%s&apos; object has no attribute &apos;%s&apos;&quot; % (self.__class__.__name__, name))\n</span><span class=\"ansigreen\">   1326</span>         jc <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>_jdf<span class=\"ansiyellow\">.</span>apply<span class=\"ansiyellow\">(</span>name<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1327</span>         <span class=\"ansigreen\">return</span> Column<span class=\"ansiyellow\">(</span>jc<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">AttributeError</span>: &apos;DataFrame&apos; object has no attribute &apos;shema&apos;</div>"]}}],"execution_count":84},{"cell_type":"code","source":["df.schema"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">19</span><span class=\"ansired\">]: </span>StructType(List(StructField(id,LongType,true),StructField(Name,StringType,true),StructField(Height,DoubleType,true),StructField(Age,LongType,true),StructField(Gender,StringType,true),StructField(Occupation,StringType,true)))\n</div>"]}}],"execution_count":85},{"cell_type":"code","source":["df.selectExpr(\"Age * 2\").show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------+\n(Age * 2)|\n+---------+\n       56|\n       90|\n     null|\n       66|\n      108|\n     null|\n       84|\n+---------+\n\n</div>"]}}],"execution_count":86},{"cell_type":"code","source":["df.sort(\"Age\",ascending = False).collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">22</span><span class=\"ansired\">]: </span>\n[Row(id=5, Name=&apos;Gregory&apos;, Height=1.8, Age=54, Gender=&apos;M&apos;, Occupation=&apos;Teacher&apos;),\n Row(id=2, Name=&apos;Fritz&apos;, Height=1.78, Age=45, Gender=&apos;M&apos;, Occupation=None),\n Row(id=7, Name=&apos;Dagmar&apos;, Height=1.7, Age=42, Gender=&apos;F&apos;, Occupation=&apos;Nurse&apos;),\n Row(id=4, Name=&apos;Nicola&apos;, Height=1.6, Age=33, Gender=&apos;F&apos;, Occupation=&apos;Dancer&apos;),\n Row(id=1, Name=&apos;Peter&apos;, Height=1.79, Age=28, Gender=&apos;M&apos;, Occupation=&apos;Tiler&apos;),\n Row(id=3, Name=&apos;Florence&apos;, Height=1.75, Age=None, Gender=None, Occupation=None),\n Row(id=6, Name=&apos;Steven&apos;, Height=1.82, Age=None, Gender=&apos;M&apos;, Occupation=None)]\n</div>"]}}],"execution_count":87},{"cell_type":"code","source":["df.orderBy(df.Age.desc()).collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">24</span><span class=\"ansired\">]: </span>\n[Row(id=5, Name=&apos;Gregory&apos;, Height=1.8, Age=54, Gender=&apos;M&apos;, Occupation=&apos;Teacher&apos;),\n Row(id=2, Name=&apos;Fritz&apos;, Height=1.78, Age=45, Gender=&apos;M&apos;, Occupation=None),\n Row(id=7, Name=&apos;Dagmar&apos;, Height=1.7, Age=42, Gender=&apos;F&apos;, Occupation=&apos;Nurse&apos;),\n Row(id=4, Name=&apos;Nicola&apos;, Height=1.6, Age=33, Gender=&apos;F&apos;, Occupation=&apos;Dancer&apos;),\n Row(id=1, Name=&apos;Peter&apos;, Height=1.79, Age=28, Gender=&apos;M&apos;, Occupation=&apos;Tiler&apos;),\n Row(id=3, Name=&apos;Florence&apos;, Height=1.75, Age=None, Gender=None, Occupation=None),\n Row(id=6, Name=&apos;Steven&apos;, Height=1.82, Age=None, Gender=&apos;M&apos;, Occupation=None)]\n</div>"]}}],"execution_count":88},{"cell_type":"code","source":["df.subtract(df).collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">27</span><span class=\"ansired\">]: </span>[]\n</div>"]}}],"execution_count":89},{"cell_type":"code","source":["df.toDF"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">28</span><span class=\"ansired\">]: </span>&lt;bound method DataFrame.toDF of DataFrame[id: bigint, Name: string, Height: double, Age: bigint, Gender: string, Occupation: string]&gt;\n</div>"]}}],"execution_count":90},{"cell_type":"code","source":[" df.toJSON().first()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">33</span><span class=\"ansired\">]: </span>&apos;{&quot;id&quot;:1,&quot;Name&quot;:&quot;Peter&quot;,&quot;Height&quot;:1.79,&quot;Age&quot;:28,&quot;Gender&quot;:&quot;M&quot;,&quot;Occupation&quot;:&quot;Tiler&quot;}&apos;\n</div>"]}}],"execution_count":91},{"cell_type":"code","source":["df.toPandas()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">34</span><span class=\"ansired\">]: </span>\n   id      Name  Height   Age Gender Occupation\n0   1     Peter    1.79  28.0      M      Tiler\n1   2     Fritz    1.78  45.0      M       None\n2   3  Florence    1.75   NaN   None       None\n3   4    Nicola    1.60  33.0      F     Dancer\n4   5   Gregory    1.80  54.0      M    Teacher\n5   6    Steven    1.82   NaN      M       None\n6   7    Dagmar    1.70  42.0      F      Nurse\n</div>"]}}],"execution_count":92},{"cell_type":"code","source":["df1 = spark.createDataFrame([[1, 2, 3]], [\"col0\", \"col1\", \"col2\"])\ndf2 = spark.createDataFrame([[4, 5, 6]], [\"col1\", \"col2\", \"col0\"])\ndf1.unionByName(df2).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----+----+----+\ncol0|col1|col2|\n+----+----+----+\n   1|   2|   3|\n   6|   4|   5|\n+----+----+----+\n\n</div>"]}}],"execution_count":93},{"cell_type":"code","source":["df = spark.createDataFrame([(1, 'Peter', 1.79, 28,'M', 'Tiler'),\n                            (2, 'Fritz', 1.78, 45,'M', None),\n                            (2, 'Florence', 1.75, None, None, None),\n                            (3, 'Nicola',1.6, 33,'F', 'Dancer'),\n                            (3, 'Gregory', 1.8, 54,'M', 'Teacher'),\n                            (4, 'Steven', 1.82, None, 'M', None),\n                            (4, 'Dagmar', 1.7, 42,'F', 'Nurse'),]\n                           , ['id', 'Name', 'Height', 'Age', 'Gender', 'Occupation'])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":94},{"cell_type":"code","source":["gdf = df.groupBy(df.id)\ngdf.agg({\"*\":\"count\"}).collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">40</span><span class=\"ansired\">]: </span>\n[Row(id=1, count(1)=1),\n Row(id=3, count(1)=2),\n Row(id=2, count(1)=2),\n Row(id=4, count(1)=2)]\n</div>"]}}],"execution_count":95},{"cell_type":"code","source":["from pyspark.sql import functions as F\ngdf.agg(F.min(df.Age)).collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">41</span><span class=\"ansired\">]: </span>\n[Row(id=1, min(Age)=28),\n Row(id=3, min(Age)=33),\n Row(id=2, min(Age)=45),\n Row(id=4, min(Age)=42)]\n</div>"]}}],"execution_count":96},{"cell_type":"code","source":["df.groupBy().avg('Age').collect()\ndf.groupBy().avg('Age','Height').collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">43</span><span class=\"ansired\">]: </span>[Row(avg(Age)=40.4, avg(Height)=1.7485714285714287)]\n</div>"]}}],"execution_count":97},{"cell_type":"code","source":["df.count()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">44</span><span class=\"ansired\">]: </span>7\n</div>"]}}],"execution_count":98},{"cell_type":"code","source":["df.groupBy().max('Age').collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">45</span><span class=\"ansired\">]: </span>[Row(max(Age)=54)]\n</div>"]}}],"execution_count":99},{"cell_type":"code","source":["df.groupBy().max('Age').collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">46</span><span class=\"ansired\">]: </span>[Row(max(Age)=54)]\n</div>"]}}],"execution_count":100},{"cell_type":"code","source":["df.groupBy().mean('Age').collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">47</span><span class=\"ansired\">]: </span>[Row(avg(Age)=40.4)]\n</div>"]}}],"execution_count":101},{"cell_type":"code","source":["df.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+--------+------+----+------+----------+\n id|    Name|Height| Age|Gender|Occupation|\n+---+--------+------+----+------+----------+\n  1|   Peter|  1.79|  28|     M|     Tiler|\n  2|   Fritz|  1.78|  45|     M|      null|\n  2|Florence|  1.75|null|  null|      null|\n  3|  Nicola|   1.6|  33|     F|    Dancer|\n  3| Gregory|   1.8|  54|     M|   Teacher|\n  4|  Steven|  1.82|null|     M|      null|\n  4|  Dagmar|   1.7|  42|     F|     Nurse|\n+---+--------+------+----+------+----------+\n\n</div>"]}}],"execution_count":102},{"cell_type":"code","source":[" df.groupBy(\"Gender\").pivot(\"Age\").max(\"Height\").show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------+----+----+----+----+----+----+\nGender|null|  28|  33|  42|  45|  54|\n+------+----+----+----+----+----+----+\n     F|null|null| 1.6| 1.7|null|null|\n  null|1.75|null|null|null|null|null|\n     M|1.82|1.79|null|null|1.78| 1.8|\n+------+----+----+----+----+----+----+\n\n</div>"]}}],"execution_count":103},{"cell_type":"code","source":["from pyspark.sql import Row\ndf = spark.createDataFrame([Row(a=170, b=75)])\ndf.select(df.a.bitwiseAND(df.b)).collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">54</span><span class=\"ansired\">]: </span>[Row((a &amp; b)=10)]\n</div>"]}}],"execution_count":104},{"cell_type":"code","source":["df = spark.createDataFrame([(1, 'Peter', 1.79, 28,'M', 'Tiler'),\n                            (2, 'Fritz', 1.78, 45,'M', None),\n                            (2, 'Florence', 1.75, None, None, None),\n                            (3, 'Nicola',1.6, 33,'F', 'Dancer'),\n                            (3, 'Gregory', 1.8, 54,'M', 'Teacher'),\n                            (4, 'Steven', 1.82, None, 'M', None),\n                            (4, 'Dagmar', 1.7, 42,'F', 'Nurse'),]\n                           , ['id', 'Name', 'Height', 'Age', 'Gender', 'Occupation'])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":105},{"cell_type":"code","source":["df.select(df.Age.cast(\"string\").alias('strin111')).collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">59</span><span class=\"ansired\">]: </span>\n[Row(strin111=&apos;28&apos;),\n Row(strin111=&apos;45&apos;),\n Row(strin111=None),\n Row(strin111=&apos;33&apos;),\n Row(strin111=&apos;54&apos;),\n Row(strin111=None),\n Row(strin111=&apos;42&apos;)]\n</div>"]}}],"execution_count":106},{"cell_type":"code","source":["df.filter(df.Name.contains('ter')).collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">60</span><span class=\"ansired\">]: </span>[Row(id=1, Name=&apos;Peter&apos;, Height=1.79, Age=28, Gender=&apos;M&apos;, Occupation=&apos;Tiler&apos;)]\n</div>"]}}],"execution_count":107},{"cell_type":"code","source":["df.filter(df.Name.endswith('ter')).collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">62</span><span class=\"ansired\">]: </span>[Row(id=1, Name=&apos;Peter&apos;, Height=1.79, Age=28, Gender=&apos;M&apos;, Occupation=&apos;Tiler&apos;)]\n</div>"]}}],"execution_count":108},{"cell_type":"code","source":[">>> from pyspark.sql import Row\n>>> df1 = spark.createDataFrame([\n...     Row(id=1, value='foo'),\n...     Row(id=2, value=None)\n... ])\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":109},{"cell_type":"code","source":["df1.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+-----+\n id|value|\n+---+-----+\n  1|  foo|\n  2| null|\n+---+-----+\n\n</div>"]}}],"execution_count":110},{"cell_type":"code","source":["df1.select(df1['id'],df1['value']).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+-----+\n id|value|\n+---+-----+\n  1|  foo|\n  2| null|\n+---+-----+\n\n</div>"]}}],"execution_count":111},{"cell_type":"code","source":["from pyspark.sql import Row\ndf1 = spark.createDataFrame([\n Row(id=1, value='foo'),\n Row(id=2, value=None)])\ndf1.select(\n           df1['value'] == 'foo',\n           df1['value'].eqNullSafe('foo'),\n           df1['value'].eqNullSafe(None)\n           ).show()\ndf2 = spark.createDataFrame([Row(value = 'bar'), Row(value = None)])\ndf1.join(df2,df1['value']== df2['value']).count()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------------+---------------+----------------+\n(value = foo)|(value &lt;=&gt; foo)|(value &lt;=&gt; NULL)|\n+-------------+---------------+----------------+\n         true|           true|           false|\n         null|          false|            true|\n+-------------+---------------+----------------+\n\n<span class=\"ansired\">Out[</span><span class=\"ansired\">87</span><span class=\"ansired\">]: </span>0\n</div>"]}}],"execution_count":112},{"cell_type":"code","source":["from pyspark.sql import Row\ndf = spark.createDataFrame([Row(r=Row(a=1, b=\"b\"))])\ndf.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------+\n     r|\n+------+\n[1, b]|\n+------+\n\n</div>"]}}],"execution_count":113},{"cell_type":"code","source":["df.select(df.r.getField('b')).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+\nr.b|\n+---+\n  b|\n+---+\n\n</div>"]}}],"execution_count":114},{"cell_type":"code","source":[" df = spark.createDataFrame([([1, 2], {\"key\": \"value\"})], [\"l\", \"d\"])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":115},{"cell_type":"code","source":["df.select(df.l.getItem(0), df.d.getItem(\"key\")).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----+------+\nl[0]|d[key]|\n+----+------+\n   1| value|\n+----+------+\n\n</div>"]}}],"execution_count":116},{"cell_type":"code","source":["df.select(df.l[0], df.d[\"key\"]).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----+------+\nl[0]|d[key]|\n+----+------+\n   1| value|\n+----+------+\n\n</div>"]}}],"execution_count":117},{"cell_type":"code","source":["df = spark.createDataFrame([(1, 'Peter', 1.79, 28,'M', 'Tiler'),\n                            (2, 'Fritz', 1.78, 45,'M', None),\n                            (2, 'Florence', 1.75, None, None, None),\n                            (3, 'Nicola',1.6, 33,'F', 'Dancer'),\n                            (3, 'Gregory', 1.8, 54,'M', 'Teacher'),\n                            (4, 'Steven', 1.82, None, 'M', None),\n                            (4, 'Dagmar', 1.7, 42,'F', 'Nurse'),]\n                           , ['id', 'Name', 'Height', 'Age', 'Gender', 'Occupation'])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":118},{"cell_type":"code","source":["df.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+--------+------+----+------+----------+\n id|    Name|Height| Age|Gender|Occupation|\n+---+--------+------+----+------+----------+\n  1|   Peter|  1.79|  28|     M|     Tiler|\n  2|   Fritz|  1.78|  45|     M|      null|\n  2|Florence|  1.75|null|  null|      null|\n  3|  Nicola|   1.6|  33|     F|    Dancer|\n  3| Gregory|   1.8|  54|     M|   Teacher|\n  4|  Steven|  1.82|null|     M|      null|\n  4|  Dagmar|   1.7|  42|     F|     Nurse|\n+---+--------+------+----+------+----------+\n\n</div>"]}}],"execution_count":119},{"cell_type":"code","source":["df.filter(df.Age.isNotNull()).collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">107</span><span class=\"ansired\">]: </span>\n[Row(id=1, Name=&apos;Peter&apos;, Height=1.79, Age=28, Gender=&apos;M&apos;, Occupation=&apos;Tiler&apos;),\n Row(id=2, Name=&apos;Fritz&apos;, Height=1.78, Age=45, Gender=&apos;M&apos;, Occupation=None),\n Row(id=3, Name=&apos;Nicola&apos;, Height=1.6, Age=33, Gender=&apos;F&apos;, Occupation=&apos;Dancer&apos;),\n Row(id=3, Name=&apos;Gregory&apos;, Height=1.8, Age=54, Gender=&apos;M&apos;, Occupation=&apos;Teacher&apos;),\n Row(id=4, Name=&apos;Dagmar&apos;, Height=1.7, Age=42, Gender=&apos;F&apos;, Occupation=&apos;Nurse&apos;)]\n</div>"]}}],"execution_count":120},{"cell_type":"code","source":["df.filter(df.Age.isNull()).collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">108</span><span class=\"ansired\">]: </span>\n[Row(id=2, Name=&apos;Florence&apos;, Height=1.75, Age=None, Gender=None, Occupation=None),\n Row(id=4, Name=&apos;Steven&apos;, Height=1.82, Age=None, Gender=&apos;M&apos;, Occupation=None)]\n</div>"]}}],"execution_count":121},{"cell_type":"code","source":["df.filter(df.Age.isin(28,45)).collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">110</span><span class=\"ansired\">]: </span>\n[Row(id=1, Name=&apos;Peter&apos;, Height=1.79, Age=28, Gender=&apos;M&apos;, Occupation=&apos;Tiler&apos;),\n Row(id=2, Name=&apos;Fritz&apos;, Height=1.78, Age=45, Gender=&apos;M&apos;, Occupation=None)]\n</div>"]}}],"execution_count":122},{"cell_type":"code","source":["df.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+--------+------+----+------+----------+\n id|    Name|Height| Age|Gender|Occupation|\n+---+--------+------+----+------+----------+\n  1|   Peter|  1.79|  28|     M|     Tiler|\n  2|   Fritz|  1.78|  45|     M|      null|\n  2|Florence|  1.75|null|  null|      null|\n  3|  Nicola|   1.6|  33|     F|    Dancer|\n  3| Gregory|   1.8|  54|     M|   Teacher|\n  4|  Steven|  1.82|null|     M|      null|\n  4|  Dagmar|   1.7|  42|     F|     Nurse|\n+---+--------+------+----+------+----------+\n\n</div>"]}}],"execution_count":123},{"cell_type":"code","source":["df.limit(2)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">117</span><span class=\"ansired\">]: </span>DataFrame[id: bigint, Name: string, Height: double, Age: bigint, Gender: string, Occupation: string]\n</div>"]}}],"execution_count":124},{"cell_type":"code","source":["df.first()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">116</span><span class=\"ansired\">]: </span>Row(id=1, Name=&apos;Peter&apos;, Height=1.79, Age=28, Gender=&apos;M&apos;, Occupation=&apos;Tiler&apos;)\n</div>"]}}],"execution_count":125},{"cell_type":"code","source":["from pyspark import HiveContext"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":126},{"cell_type":"code","source":["df = spark.createDataFrame([(1, 'Peter', 1.79, 28,'M', 'Tiler'),\n                            (2, 'Fritz', 1.78, 45,'M', None),\n                            (2, 'Florence', 1.75, None, None, None),\n                            (3, 'Nicola',1.6, 33,'F', 'Dancer'),\n                            (3, 'Gregory', 1.8, 54,'M', 'Teacher'),\n                            (4, 'Steven', 1.82, None, 'M', None),\n                            (4, 'Dagmar', 1.7, 42,'F', 'Nurse'),]\n                           , ['id', 'Name', 'Height', 'Age', 'Gender', 'Occupation'])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":127},{"cell_type":"code","source":["from pyspark.sql.functions import regexp_replace\nfrom pyspark.sql.functions import col\nregexp_string = \"Peter|Fritz\"\ndf.select(regexp_replace(col('name'),regexp_string,'Karthikeyan')).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------------------------------------------+\nregexp_replace(name, Peter|Fritz, Karthikeyan)|\n+----------------------------------------------+\n                                   Karthikeyan|\n                                   Karthikeyan|\n                                      Florence|\n                                        Nicola|\n                                       Gregory|\n                                        Steven|\n                                        Dagmar|\n+----------------------------------------------+\n\n</div>"]}}],"execution_count":128},{"cell_type":"code","source":["from pyspark.sql.functions import to_date, lit\nspark.range(5).withColumn('date',lit(\"2017-01-01\"))\\\n     .select(to_date(col('date'))).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------------+\nto_date(&#96;date&#96;)|\n+---------------+\n     2017-01-01|\n     2017-01-01|\n     2017-01-01|\n     2017-01-01|\n     2017-01-01|\n+---------------+\n\n</div>"]}}],"execution_count":129},{"cell_type":"code","source":["df = spark.createDataFrame([(1, 'Peter', 1.79, 28,'M', 'Tiler'),\n                            (2, 'Fritz', 1.78, 45,'M', None),\n                            (2, 'Florence', 1.75, None, None, None),\n                            (3, 'Nicola',1.6, 33,'F', 'Dancer'),\n                            (3, 'Gregory', 1.8, 54,'M', 'Teacher'),\n                            (4, 'Steven', 1.82, None, 'M', None),\n                            (4, 'Dagmar', 1.7, 42,'F', 'Nurse'),]\n                           , ['id', 'Name', 'Height', 'Age', 'Gender', 'Occupation'])\n\n\nfrom pyspark.sql.functions import struct\nfrom pyspark.sql.functions import col\ncomplexDF = df.select(struct('Name','Height')).alias('complex')\ncomplexDF.show()\ncomplexDF = df.select(struct(\"Name\", \"Height\").alias(\"complex\"))\ncomplexDF.select(\"complex.Name\").show()\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------------------------------------+\nnamed_struct(Name, Name, Height, Height)|\n+----------------------------------------+\n                           [Peter, 1.79]|\n                           [Fritz, 1.78]|\n                        [Florence, 1.75]|\n                           [Nicola, 1.6]|\n                          [Gregory, 1.8]|\n                          [Steven, 1.82]|\n                           [Dagmar, 1.7]|\n+----------------------------------------+\n\n+--------+\n    Name|\n+--------+\n   Peter|\n   Fritz|\nFlorence|\n  Nicola|\n Gregory|\n  Steven|\n  Dagmar|\n+--------+\n\n</div>"]}}],"execution_count":130},{"cell_type":"code","source":["df = spark.createDataFrame([(1, 'Karthikeyan Rasipalayam Durairaj Sakunthalla Navaneethan Nalini', 1.79, 28,'M', 'Tiler')\n                            ]\n                           , ['id', 'Name', 'Height', 'Age', 'Gender', 'Occupation'])"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":131},{"cell_type":"code","source":["df.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+--------------------+------+---+------+----------+\n id|                Name|Height|Age|Gender|Occupation|\n+---+--------------------+------+---+------+----------+\n  1|Karthikeyan Rasip...|  1.79| 28|     M|     Tiler|\n+---+--------------------+------+---+------+----------+\n\n</div>"]}}],"execution_count":132},{"cell_type":"code","source":["from pyspark.sql.functions import size\nfrom pyspark.sql.functions import col\nfrom pyspark.sql.functions import split\ndf.select(size(split(col('Name'),\" \"))).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+\nsize(split(Name,  ))|\n+--------------------+\n                   6|\n+--------------------+\n\n</div>"]}}],"execution_count":133},{"cell_type":"code","source":["df = spark.createDataFrame([(1, 'Karthikeyan Rasipalayam Durairaj Sakunthalla Navaneethan Nalini', 1.79, 28,'M', 'Tiler')\n                            ]\n                           , ['id', 'Name', 'Height', 'Age', 'Gender', 'Occupation'])\n\nfrom pyspark.sql.functions import array_contains\nfrom pyspark.sql.functions import split,col\ndf.select(array_contains(split(col('name'),' '),'Amma')).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------------------------------------+\narray_contains(split(name,  ), Amma)|\n+------------------------------------+\n                               false|\n+------------------------------------+\n\n</div>"]}}],"execution_count":134},{"cell_type":"code","source":["from pyspark.sql.functions import array_contains\nfrom pyspark.sql.functions import split,col\ndf = spark.createDataFrame([(1, 'Karthikeyan Rasipalayam Durairaj Sakunthalla Navaneethan Nalini', 1.79, 28,'M', 'Tiler')\n                            ]\n                           , ['id', 'Name', 'Height', 'Age', 'Gender', 'Occupation'])\n\ndf.select(array_contains(split(col('name'),' '),'Amma')).show()\n\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------------------------------------+\narray_contains(split(name,  ), Amma)|\n+------------------------------------+\n                               false|\n+------------------------------------+\n\n</div>"]}}],"execution_count":135},{"cell_type":"code","source":["from pyspark.sql.functions import split,explode\nfrom pyspark.sql.functions import split\ndf.withColumn(\"splitted\",split(col(\"Name\"),\" \"))\\\n  .withColumn(\"explode\",explode(col(\"splitted\")))\\\n  .select('splitted','explode').show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+-----------+\n            splitted|    explode|\n+--------------------+-----------+\n[Karthikeyan, Ras...|Karthikeyan|\n[Karthikeyan, Ras...|Rasipalayam|\n[Karthikeyan, Ras...|   Durairaj|\n[Karthikeyan, Ras...|Sakunthalla|\n[Karthikeyan, Ras...|Navaneethan|\n[Karthikeyan, Ras...|     Nalini|\n+--------------------+-----------+\n\n</div>"]}}],"execution_count":136},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":137}],"metadata":{"name":"Dataframe References","notebookId":2274473968880735},"nbformat":4,"nbformat_minor":0}
