{"cells":[{"cell_type":"code","source":["'''\nSpark SQL : \n\nThis provides three main capabilities :\n\n1. Loading the varirty of stucrtured sources ( JSON,Hive,Parquet)\n2. We can query by using SQL \n3. Spark SQL provides rich integration between SQL and requler Python\n\n* To implement these capabilities, spark SQL provides special data objects RDD called schema RDD. \n* Spark SQL can be build with or without Apache hive , hadoop sql engine \n* Two entry point : HiveContext, SQLcontext \n* HiveContext is depends upon the hive accesss\n* SQLContext is depends upon the non-hive access \n\nSpark Runtime Explaineation : \n\nhttps://www.youtube.com/watch?v=rJFg2i_auAg\n\nDAG learning :\n\nGrapgh Therory : https://www.youtube.com/watch?v=i-_vWc4Pcck\nDAG model : https://techvidvan.com/tutorials/apache-spark-dag-directed-acyclic-graph/\n\nDynamic allocation & External Shuffle Services: \n\nhttps://www.youtube.com/watch?v=-9bh_Oue9GM&t=509s\n\n\n'''"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["from pyspark import SQLContext\nfrom pyspark import HiveContext"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["hivctx = HiveContext(sc)\nsqlctx = SQLContext(sc)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["a = sc.parallelize([1,2,3])\nprint(a.toDebugString())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">b&apos;(8) ParallelCollectionRDD[38] at parallelize at PythonRDD.scala:267 []&apos;\n</div>"]}}],"execution_count":4},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":5}],"metadata":{"name":"09_Chapter_spark","notebookId":3025640379216798},"nbformat":4,"nbformat_minor":0}
