{"cells":[{"cell_type":"code","source":["from pyspark import SQLContext\nfrom pyspark import HiveContext\nfrom pyspark.sql import Row\ndf = spark.read.format('csv').load ('dbfs:/FileStore/tables/employeetable.csv',header = True)\ndf.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------+------------+----------+------+\nempid |    empname | location |salary|\n+------+------------+----------+------+\n   100|karthikeyan |   chennai|  1003|\n   200| navaneethan|coimbatore|  2004|\n   300|      nalini|   madurai|  3005|\n   400|     prakash|coimbatore|  4006|\n   500| nivedhithaa|  dindugal|  5007|\n+------+------------+----------+------+\n\n</div>"]}}],"execution_count":1},{"cell_type":"code","source":["df.count()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">8</span><span class=\"ansired\">]: </span>5\n</div>"]}}],"execution_count":2},{"cell_type":"code","source":["df.select('location ').count()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">11</span><span class=\"ansired\">]: </span>5\n</div>"]}}],"execution_count":3},{"cell_type":"code","source":["from pyspark.sql.functions import countDistinct \ndf.select(countDistinct(\"location \")).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------------------------+\ncount(DISTINCT location )|\n+-------------------------+\n                        4|\n+-------------------------+\n\n</div>"]}}],"execution_count":4},{"cell_type":"code","source":["#approx_count_distinct\nfrom pyspark.sql.functions import approx_count_distinct\ndf.select(approx_count_distinct(\"location \")).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------------------+\napprox_count_distinct(location )|\n+--------------------------------+\n                               3|\n+--------------------------------+\n\n</div>"]}}],"execution_count":5},{"cell_type":"code","source":["#first,last\nfrom pyspark.sql.functions import first,last\ndf.select(first('location '),last('location ')).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------------------+----------------------+\nfirst(location , false)|last(location , false)|\n+-----------------------+----------------------+\n                chennai|              dindugal|\n+-----------------------+----------------------+\n\n</div>"]}}],"execution_count":6},{"cell_type":"code","source":["#min,max\nfrom pyspark.sql.functions import min,max\ndf.select(min(\"salary\"),max(\"salary\")).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------+-----------+\nmin(salary)|max(salary)|\n+-----------+-----------+\n       1003|       5007|\n+-----------+-----------+\n\n</div>"]}}],"execution_count":7},{"cell_type":"code","source":["#Suppose If we select non numeric value selected \nfrom pyspark.sql.functions import min ,max\ndf.select(min(\"empname \"),max(\"empname \")).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-------------+-------------+\nmin(empname )|max(empname )|\n+-------------+-------------+\n karthikeyan |      prakash|\n+-------------+-------------+\n\n</div>"]}}],"execution_count":8},{"cell_type":"code","source":["#sum \n\nfrom pyspark.sql.functions import sum\ndf.select(sum(\"salary\")).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------+\nsum(salary)|\n+-----------+\n    15025.0|\n+-----------+\n\n</div>"]}}],"execution_count":9},{"cell_type":"code","source":["#SumDistinct\nfrom pyspark.sql.functions import sumDistinct\ndf.select(sumDistinct(\"salary\")).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+\nsum(DISTINCT salary)|\n+--------------------+\n             15025.0|\n+--------------------+\n\n</div>"]}}],"execution_count":10},{"cell_type":"code","source":["#avg,mean,\nfrom pyspark.sql.functions import avg,sum\ndf.select(avg(\"salary\"),sum(\"salary\")).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----------+-----------+\navg(salary)|sum(salary)|\n+-----------+-----------+\n     3005.0|    15025.0|\n+-----------+-----------+\n\n</div>"]}}],"execution_count":11},{"cell_type":"code","source":["from pyspark.sql.functions import count\ndf.groupBy(\"location \")\\\n  .agg(count(\"*\")).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------+--------+\n location |count(1)|\n+----------+--------+\n   chennai|       1|\n  dindugal|       1|\n   madurai|       1|\ncoimbatore|       2|\n+----------+--------+\n\n</div>"]}}],"execution_count":12},{"cell_type":"code","source":["# import packages\nimport os\nfrom pyspark import SparkContext, SparkConf\nimport numpy as np\n# import seaborn as sns\n# sns.set(rc={'figure.figsize':(15,5)},font_scale=1.2)\n# color = [\"#e74c3c\", \"#2ecc71\"]\n# sns.set_palette(color)\n# sns.set_style(\"whitegrid\")\nimport matplotlib.pyplot as plt\n\nimport pandas as pd\npd.set_option('display.max_columns', None) \npd.set_option('display.max_rows', None)\n\n\nprint(os.environ['SPARK_HOME'])\nfrom pyspark.sql import SparkSession, HiveContext, SQLContext\nfrom pyspark.sql.functions import when, desc\nfrom pyspark.sql.types import *\nfrom pyspark.sql import Row, functions as F\nfrom pyspark.sql.functions import to_date, trunc, unix_timestamp, date_format\nfrom pyspark.sql.window import Window\nfrom datetime import datetime"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/spark\n</div>"]}}],"execution_count":13},{"cell_type":"code","source":["#Window Function \nfrom pyspark.sql.window import Window\nfrom pyspark.sql.functions import desc\n# = Window.partitionBy('store_nbr', 'rx_nbr', 'rx_fill_nbr').orderBy(F.col('run_dt'))\nwindow = Window\\\n               .partitionBy('location ')\\\n               .orderBy('salary')\ndf.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------+------------+----------+------+\nempid |    empname | location |salary|\n+------+------------+----------+------+\n   100|karthikeyan |   chennai|  1003|\n   200| navaneethan|coimbatore|  2004|\n   300|      nalini|   madurai|  3005|\n   400|     prakash|coimbatore|  4006|\n   500| nivedhithaa|  dindugal|  5007|\n+------+------------+----------+------+\n\n</div>"]}}],"execution_count":14},{"cell_type":"code","source":["from pyspark.sql.functions import rank\ndf1 = df.select('location ','salary',rank().over(window).alias('rankcol'))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":15},{"cell_type":"code","source":["df1.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------+------+-------+\n location |salary|rankcol|\n+----------+------+-------+\n   chennai|  1003|      1|\n  dindugal|  5007|      1|\n   madurai|  3005|      1|\ncoimbatore|  2004|      1|\ncoimbatore|  4006|      2|\n+----------+------+-------+\n\n</div>"]}}],"execution_count":16},{"cell_type":"code","source":["df1.printSchema()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- location : string (nullable = true)\n-- salary: string (nullable = true)\n-- rankcol: integer (nullable = true)\n\n</div>"]}}],"execution_count":17},{"cell_type":"code","source":["df1.filter(col(\"rankcol\") == 1).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------+------+-------+\n location |salary|rankcol|\n+----------+------+-------+\n   chennai|  1003|      1|\n  dindugal|  5007|      1|\n   madurai|  3005|      1|\ncoimbatore|  2004|      1|\n+----------+------+-------+\n\n</div>"]}}],"execution_count":18},{"cell_type":"code","source":["#Grouping set \ndf.show()\ndf.registerTempTable(\"test\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-1133364376476616&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      1</span> <span class=\"ansired\">#Grouping set</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">----&gt; 2</span><span class=\"ansiyellow\"> </span>df<span class=\"ansiyellow\">.</span>show<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      3</span> df<span class=\"ansiyellow\">.</span>registerTempTable<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;test&quot;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">NameError</span>: name &apos;df&apos; is not defined</div>"]}}],"execution_count":19},{"cell_type":"code","source":["from pyspark import SQLContext\nfrom pyspark import HiveContext\nfrom pyspark.sql import Row\ndf = spark.read.format('csv').load ('dbfs:/FileStore/tables/employeetable.csv',header = True)\ndf.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------+------------+----------+------+\nempid |    empname | location |salary|\n+------+------------+----------+------+\n   100|karthikeyan |   chennai|  1003|\n   200| navaneethan|coimbatore|  2004|\n   300|      nalini|   madurai|  3005|\n   400|     prakash|coimbatore|  4006|\n   500| nivedhithaa|  dindugal|  5007|\n+------+------------+----------+------+\n\n</div>"]}}],"execution_count":20},{"cell_type":"code","source":["#rollup\nfrom pyspark.sql.functions import count\ndf.rollup(\"location \")\\\n  .agg(count(\"*\")).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------+--------+\n location |count(1)|\n+----------+--------+\n  dindugal|       1|\n      null|       5|\n   madurai|       1|\ncoimbatore|       2|\n   chennai|       1|\n+----------+--------+\n\n</div>"]}}],"execution_count":21},{"cell_type":"code","source":["# cube \nfrom pyspark.sql.functions import sum\ndf.cube(\"location \",\"empname \")\\\n  .agg(count(\"*\")).orderBy(\"location \").show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------+------------+--------+\n location |    empname |count(1)|\n+----------+------------+--------+\n      null| navaneethan|       1|\n      null|        null|       5|\n      null|      nalini|       1|\n      null|karthikeyan |       1|\n      null|     prakash|       1|\n      null| nivedhithaa|       1|\n   chennai|karthikeyan |       1|\n   chennai|        null|       1|\ncoimbatore|        null|       2|\ncoimbatore|     prakash|       1|\ncoimbatore| navaneethan|       1|\n  dindugal|        null|       1|\n  dindugal| nivedhithaa|       1|\n   madurai|      nalini|       1|\n   madurai|        null|       1|\n+----------+------------+--------+\n\n</div>"]}}],"execution_count":22},{"cell_type":"code","source":["#rollup\nfrom pyspark.sql.functions import count\ndf_pivoted  = df.groupBy(\"location \")\\\n  .pivot(\"salary\").sum()\n\ndf_pivoted.show() "],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------+\n location |\n+----------+\n   chennai|\n  dindugal|\n   madurai|\ncoimbatore|\n+----------+\n\n</div>"]}}],"execution_count":23},{"cell_type":"code","source":["from pyspark import SQLContext\nfrom pyspark import HiveContext\nfrom pyspark.sql import Row\ndf = spark.read.format('csv').load ('dbfs:/FileStore/tables/employeetable.csv',header = True)\ndf.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------+------------+----------+------+\nempid |    empname | location |salary|\n+------+------------+----------+------+\n   100|karthikeyan |   chennai|  1003|\n   200| navaneethan|coimbatore|  2004|\n   300|      nalini|   madurai|  3005|\n   400|     prakash|coimbatore|  4006|\n   500| nivedhithaa|  dindugal|  5007|\n+------+------------+----------+------+\n\n</div>"]}}],"execution_count":24},{"cell_type":"code","source":["from pyspark.sql import functions as F\ndf.agg(F.min(df.salary)).collect()\ndf.agg({'salary':'max'}).collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">7</span><span class=\"ansired\">]: </span>[Row(max(salary)=&apos;5007&apos;)]\n</div>"]}}],"execution_count":25},{"cell_type":"code","source":["from pyspark.sql import functions as F\ndf.agg({'salary':'max'}).collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">9</span><span class=\"ansired\">]: </span>[Row(max(salary)=&apos;5007&apos;)]\n</div>"]}}],"execution_count":26},{"cell_type":"code","source":["from pyspark.sql import functions as F\ndf.agg({'salary':'max'}).collect()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">10</span><span class=\"ansired\">]: </span>[Row(max(salary)=&apos;5007&apos;)]\n</div>"]}}],"execution_count":27},{"cell_type":"code","source":["df.dtypes"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">11</span><span class=\"ansired\">]: </span>\n[(&apos;empid &apos;, &apos;string&apos;),\n (&apos;empname &apos;, &apos;string&apos;),\n (&apos;location &apos;, &apos;string&apos;),\n (&apos;salary&apos;, &apos;string&apos;)]\n</div>"]}}],"execution_count":28},{"cell_type":"code","source":["df.schema"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">12</span><span class=\"ansired\">]: </span>StructType(List(StructField(empid ,StringType,true),StructField(empname ,StringType,true),StructField(location ,StringType,true),StructField(salary,StringType,true)))\n</div>"]}}],"execution_count":29},{"cell_type":"code","source":["from pyspark.sql.functions import col\ndf = sqlContext.createDataFrame(\n    [('cat \\n\\n elephant rat \\n rat cat', )], ['word']\n)\n\ndf.select(explode(split(col(\"word\"), \"\\s+\")).alias(\"word\")).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------+\n    word|\n+--------+\n     cat|\nelephant|\n     rat|\n     rat|\n     cat|\n+--------+\n\n</div>"]}}],"execution_count":30},{"cell_type":"code","source":["# import pyspark class Row from module sql\nfrom pyspark.sql import *\n\n# Create Example Data - Departments and Employees\n\n# Create the Departments\ndepartment1 = Row(id='123456', name='Computer Science')\ndepartment2 = Row(id='789012', name='Mechanical Engineering')\ndepartment3 = Row(id='345678', name='Theater and Drama')\ndepartment4 = Row(id='901234', name='Indoor Recreation')\n\n# Create the Employees\nEmployee = Row(\"firstName\", \"lastName\", \"email\", \"salary\")\nemployee1 = Employee('michael', 'armbrust', 'no-reply@berkeley.edu', 100000)\nemployee2 = Employee('xiangrui', 'meng', 'no-reply@stanford.edu', 120000)\nemployee3 = Employee('matei', None, 'no-reply@waterloo.edu', 140000)\nemployee4 = Employee(None, 'wendell', 'no-reply@berkeley.edu', 160000)\n\n# Create the DepartmentWithEmployees instances from Departments and Employees\ndepartmentWithEmployees1 = Row(department=department1, employees=[employee1, employee2])\ndepartmentWithEmployees2 = Row(department=department2, employees=[employee3, employee4])\ndepartmentWithEmployees3 = Row(department=department3, employees=[employee1, employee4])\ndepartmentWithEmployees4 = Row(department=department4, employees=[employee2, employee3])\n\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":31},{"cell_type":"code","source":["departmentsWithEmployeesSeq1 = [departmentWithEmployees1, departmentWithEmployees2]\ndf1 = spark.createDataFrame(departmentsWithEmployeesSeq1)\n\ndisplay(df1)\n\ndepartmentsWithEmployeesSeq2 = [departmentWithEmployees3, departmentWithEmployees4]\ndf2 = spark.createDataFrame(departmentsWithEmployeesSeq2)\n\ndisplay(df2)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>department</th><th>employees</th></tr></thead><tbody><tr><td>List(345678, Theater and Drama)</td><td>List(List(michael, armbrust, no-reply@berkeley.edu, 100000), List(null, wendell, no-reply@berkeley.edu, 160000))</td></tr><tr><td>List(901234, Indoor Recreation)</td><td>List(List(xiangrui, meng, no-reply@stanford.edu, 120000), List(matei, null, no-reply@waterloo.edu, 140000))</td></tr></tbody></table></div>"]}}],"execution_count":32},{"cell_type":"code","source":["unionDF = df1.unionAll(df2)\ndisplay(unionDF)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>department</th><th>employees</th></tr></thead><tbody><tr><td>List(123456, Computer Science)</td><td>List(List(michael, armbrust, no-reply@berkeley.edu, 100000), List(xiangrui, meng, no-reply@stanford.edu, 120000))</td></tr><tr><td>List(789012, Mechanical Engineering)</td><td>List(List(matei, null, no-reply@waterloo.edu, 140000), List(null, wendell, no-reply@berkeley.edu, 160000))</td></tr><tr><td>List(345678, Theater and Drama)</td><td>List(List(michael, armbrust, no-reply@berkeley.edu, 100000), List(null, wendell, no-reply@berkeley.edu, 160000))</td></tr><tr><td>List(901234, Indoor Recreation)</td><td>List(List(xiangrui, meng, no-reply@stanford.edu, 120000), List(matei, null, no-reply@waterloo.edu, 140000))</td></tr></tbody></table></div>"]}}],"execution_count":33},{"cell_type":"code","source":["df = unionDF.select(explode(\"employees\").alias(\"e\"))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":34},{"cell_type":"code","source":["df.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+--------------------+\n                   e|\n+--------------------+\n[michael, armbrus...|\n[xiangrui, meng, ...|\n[matei,, no-reply...|\n[, wendell, no-re...|\n[michael, armbrus...|\n[, wendell, no-re...|\n[xiangrui, meng, ...|\n[matei,, no-reply...|\n+--------------------+\n\n</div>"]}}],"execution_count":35},{"cell_type":"code","source":["explodeDF =df.selectExpr(\"e.firstname\",\"e.lastname\",\"e.email\",\"e.salary\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":36},{"cell_type":"code","source":["explodeDF.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---------+--------+--------------------+------+\nfirstname|lastname|               email|salary|\n+---------+--------+--------------------+------+\n  michael|armbrust|no-reply@berkeley...|100000|\n xiangrui|    meng|no-reply@stanford...|120000|\n    matei|    null|no-reply@waterloo...|140000|\n     null| wendell|no-reply@berkeley...|160000|\n  michael|armbrust|no-reply@berkeley...|100000|\n     null| wendell|no-reply@berkeley...|160000|\n xiangrui|    meng|no-reply@stanford...|120000|\n    matei|    null|no-reply@waterloo...|140000|\n+---------+--------+--------------------+------+\n\n</div>"]}}],"execution_count":37},{"cell_type":"code","source":["explodeDF.printSchema()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- firstname: string (nullable = true)\n-- lastname: string (nullable = true)\n-- email: string (nullable = true)\n-- salary: long (nullable = true)\n\n</div>"]}}],"execution_count":38},{"cell_type":"code","source":["filterDF = explodeDF.filter(explodeDF.firstname == \"xiangrui\").sort(explodeDF.lastname)\ndisplay(filterDF)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>firstname</th><th>lastname</th><th>email</th><th>salary</th></tr></thead><tbody><tr><td>xiangrui</td><td>meng</td><td>no-reply@stanford.edu</td><td>120000</td></tr><tr><td>xiangrui</td><td>meng</td><td>no-reply@stanford.edu</td><td>120000</td></tr></tbody></table></div>"]}}],"execution_count":39},{"cell_type":"code","source":["df = spark.createDataFrame([(1, \"A\", [1,2,3]), (2, \"B\", [3,5])],[\"col1\", \"col2\", \"col3\"])\nfrom pyspark.sql.functions import explode\ndf.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----+----+---------+\ncol1|col2|     col3|\n+----+----+---------+\n   1|   A|[1, 2, 3]|\n   2|   B|   [3, 5]|\n+----+----+---------+\n\n</div>"]}}],"execution_count":40},{"cell_type":"code","source":["df.withColumn(\"col3\", explode(df.col3)).show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----+----+----+\ncol1|col2|col3|\n+----+----+----+\n   1|   A|   1|\n   1|   A|   2|\n   1|   A|   3|\n   2|   B|   3|\n   2|   B|   5|\n+----+----+----+\n\n</div>"]}}],"execution_count":41},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":42}],"metadata":{"name":"Aggregation Functions","notebookId":42730556704585},"nbformat":4,"nbformat_minor":0}
